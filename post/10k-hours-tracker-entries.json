{
  "postId": "10k-hours-tracker",
  "entries": [
    {
      "id": 1,
      "timestamp": "2026-02-04T00:00:00Z",
      "title": "Idea: Aplicaci√≥n 10K Hours Tracker",
      "text": "Se me ocurri√≥ crear una aplicaci√≥n para trackear las horas que dedico a diferentes temas o habilidades. La inspiraci√≥n viene de la Teor√≠a de las 10,000 horas de Malcolm Gladwell, que propone que se necesitan aproximadamente 10,000 horas de pr√°ctica deliberada para alcanzar el nivel de experto en cualquier disciplina.\n\nConcepto de la interfaz: La visualizaci√≥n estar√≠a inspirada en el contribution graph de GitHub (ese calendario con cuadros verdes que muestra la actividad de commits). Quiero que el usuario pueda ver su progreso de forma visual y clara, similar a c√≥mo GitHub representa la actividad diaria.\n\nFuncionalidad principal: El usuario podr√° registrar su progreso d√≠a a d√≠a. Por ejemplo: 'Hoy practiqu√© 3 horas de piano' se registra, y la app ir√° acumulando y visualizando todo el historial de pr√°ctica, mostrando el avance hacia la meta de las 10,000 horas.\n\nPr√≥ximos pasos: Tengo planeada una integraci√≥n adicional con IA, pero eso lo detallar√© en la siguiente nota."
    },
    {
      "id": 2,
      "timestamp": "2026-02-04T01:00:00Z",
      "title": "Stack T√©cnico y Primeros Pasos",
      "text": "Durante estas sesiones ir√© documentando todo el progreso del desarrollo. Ser√° una app Android por el momento, ya que es m√°s sencillo desplegarla.\n\nMetodolog√≠a: El desarrollo ser√° principalmente mediante vibe coding - yo genero las instrucciones y Claude Sonnet 4.5 se encarga de escribir todo el c√≥digo, la base de datos, y los requerimientos t√©cnicos/funcionales. El objetivo es no escribir absolutamente una sola l√≠nea de c√≥digo manualmente.\n\nStack tecnol√≥gico: Runtime Bun (extremadamente r√°pido), Backend con Hono (framework web), Base de datos PostgreSQL, y ORM Prisma.\n\nEsquema de base de datos actual: Claude Code ya gener√≥ un esquema inicial bastante bueno con tres tablas principales: User (tabla de usuarios), Skills (los temas o habilidades que queremos trackear, ej: piano, programaci√≥n), y Sessions (las horas registradas, relacionadas a cada skill).\n\nEstado actual: Estoy trabajando en los endpoints de registro de usuario. Ya tengo los requerimientos t√©cnicos definidos y voy a crear pruebas automatizadas para validar el flujo de registro."
    },
    {
      "id": 3,
      "timestamp": "2026-02-04T02:00:00Z",
      "title": "Dise√±o UI, Flutter y Arquitectura Limpia",
      "text": "He estado revisando algunos temas y paletas de color para ver c√≥mo pudiera hacer la aplicaci√≥n. Estoy pensando seriamente en un verde, pero no lo s√©, como con verdes un poco raro pero probablemente s√≠, dependiendo de c√≥mo se vea. Por ah√≠ voy a decirle a Claude que me genere un tema para Flutter.\n\nYo la neta no s√© nada de Flutter, literal no s√© nada de Flutter. Entonces ¬øc√≥mo le voy a hacer para saber si voy por el lugar correcto, que est√° escribiendo las instrucciones correctas? Pues por ah√≠ utilic√© instrucciones bien definidas que investigu√©, o que la misma gente tambi√©n investig√≥ y que sabe c√≥mo tener una buena arquitectura y una buena estructura en Flutter.\n\nQuiero evitar que se creen archivos muy gigantes porque me ha pasado en el pasado que el LLM como que en Flutter crea archivos demasiado grandes. Y pues queremos evitar eso porque para la ventana del contexto de un LLM es mucho m√°s complicado leer un archivo que es muy grande - es m√°s sencillo que el LLM lea archivos peque√±os y tenga como que mayor contexto del problema al que se va a enfrentar.\n\nProgreso actual: Parece que ya puedo registrarme, voy a hacer el login. Por ah√≠ lanc√© unas pruebas de integraci√≥n tambi√©n totalmente automatizadas. Ahora mismo estoy viendo la interfaz de usuario, cu√°l ser√° el mejor dise√±o. Estoy viendo algunos buenos dise√±os y los voy a pasar al modelo para que analice las im√°genes y a partir de ah√≠ ya me genere pues algo bello. ¬°Vamos a ver qu√© onda raza!"
    },
    {
      "id": 4,
      "timestamp": "2026-02-04T08:45:10Z",
      "title": "Login, Backend y Perfil de Usuario",
      "text": "Al final, si optamos por usar el tema verde, entonces as√≠ vamos a dise√±ar la aplicaci√≥n con ese tema verde-cinch. Ya logramos crear el login conectado con el backend. Lanc√© unas pruebas y todo pas√≥ correctamente. Tambi√©n logramos conectar Nodemailer para mandar correos de verificaci√≥n en el login, con un c√≥digo de verificaci√≥n que el usuario debe ingresar cuando se registra.\n\nVi un dise√±o de navegador, un tabulador (App Tab) en Google que me gust√≥ mucho. El modelo lo replic√≥ muy bien; se ve excelente.\n\nLogr√© crear la secci√≥n de perfil donde se muestran los datos del usuario: correo, nombre, la opci√≥n para cambiar contrase√±a y un bot√≥n para cerrar sesi√≥n. Sin embargo, el bot√≥n para cerrar sesi√≥n no est√° funcionando correctamente; devuelve una excepci√≥n. Voy a investigar por qu√© ocurre esto.\n\nHasta aqu√≠ mi reporte.",
      "image": "post/entry-4-app-tab.png",
      "imageCaption": "Dise√±o del App Tab replicado por el modelo"
    },
    {
      "id": 5,
      "timestamp": "2026-02-05T02:14:37Z",
      "title": "M√≥dulo de Skills, Cron√≥metro y Rachas",
      "text": "## Resumen del avance del 4 de febrero de 2026\n\nHoy implementamos el m√≥dulo completo de **Skills** con las siguientes funcionalidades:\n\n### CRUD de Skills\n- **Crear** un nuevo skill para dar seguimiento a las 10,000 horas\n- **Editar** skill: cambiar t√≠tulo, emoji y color de la interfaz\n- **Eliminar** skills\n\n### Cron√≥metro de Pr√°ctica\nImplementamos un cron√≥metro que cuenta las horas de pr√°ctica en tiempo real:\n- En la interfaz se visualiza el tiempo transcurrido\n- En la app m√≥vil funciona en background con notificaciones mostrando el progreso\n- Al detener el cron√≥metro se genera autom√°ticamente una nueva entrada de sesi√≥n\n\n### Sesiones Manuales\nTambi√©n se puede crear una sesi√≥n de forma manual con:\n- T√≠tulo personalizado\n- Comentarios sobre la pr√°ctica\n- Fecha espec√≠fica\n\n*Aunque el cron√≥metro es m√°s intuitivo y conveniente.*\n\n### Sistema de Rachas (Streaks)\nAgregamos la funcionalidad de rachas en el header:\n- Muestra el n√∫mero de d√≠as consecutivos de pr√°ctica\n- Sirve como incentivo y motivaci√≥n para no perder la racha\n\n### Visualizador tipo GitHub\nImplementamos un visualizador de actividad estilo GitHub (contribution graph). Por el momento funciona bien, pero se puede mejorar en futuras iteraciones.\n\n---\n\n**Estado:** Las funcionalidades principales est√°n completas. Quedan algunos ajustes de UI por pulir.",
      "image": "post/entry-5-skills-module.png",
      "imageCaption": "M√≥dulo de Skills con cron√≥metro y visualizador de actividad"
    },
    {
      "id": 6,
      "timestamp": "2026-02-05T08:45:04Z",
      "title": "Temporizador Minimalista y M√≥dulo de Resumen",
      "text": "## Avances del 5 de febrero de 2026\n\nHoy trabajamos en varias mejoras importantes para la experiencia de usuario.\n\n### Temporizador Redise√±ado\nEl temporizador ahora es **m√°s minimalista** porque la versi√≥n anterior ocupaba demasiado espacio en pantalla:\n- Corre en **background** cuando cierras la aplicaci√≥n\n- Muestra el progreso en las **notificaciones** del sistema\n- Al dar clic en la notificaci√≥n, abre la app autom√°ticamente\n\n### Nueva Navegaci√≥n (Tab Nav)\nRedise√±amos el navegador inferior con tres secciones:\n- üè† **Home** - Casita como pantalla principal\n- ‚ù§Ô∏è **Resumen General** - Nuevo m√≥dulo central\n- üë§ **Perfil** - Configuraci√≥n del usuario\n\n### M√≥dulo de Resumen General\nEste nuevo m√≥dulo muestra estad√≠sticas consolidadas:\n- **Total de horas** acumuladas en todos los skills\n- **N√∫mero de skills** que est√°s trackeando\n- **Media promedio** de horas por skill\n- üìä **Gr√°fica de horas por mes** - Visualizaci√≥n del progreso mensual vs mes anterior\n\n### Fecha Estimada de Meta\nAgregamos una caracter√≠stica muy √∫til:\n- Calcula **cu√°ndo alcanzar√°s las 10,000 horas** bas√°ndose en tu historial\n- Te dice si faltan 10, 20, 140 d√≠as... seg√∫n tu ritmo actual\n\n### Rachas por Skill\nAhora puedes ver la **racha individual** de cada skill en una lista dedicada.\n\n---\n\n**Pr√≥ximo paso:** Estoy trabajando en un **onboarding para nuevos usuarios** que explicar√° en qu√© consiste la app, guiar√° la creaci√≥n del primer skill y dar√° una vista general de las funcionalidades.",
      "image": "post/entry-6-summary-module.png",
      "imageCaption": "Nuevo m√≥dulo de resumen general con estad√≠sticas"
    },
    {
      "id": 7,
      "timestamp": "2026-02-06T09:21:02Z",
      "title": "Logo, Redise√±o del Home y Compartir en Instagram",
      "text": "## Avances del 6 de febrero de 2026 ‚Äî Devlog D√≠a 3\n\nHoy fue un d√≠a bastante productivo. Trabajamos en identidad visual, mejoras de UX y un feature que creemos va a darle mucha tracci√≥n a la app.\n\n### üé® Nuevo Logo\nCreamos un logotipo minimalista inspirado en el grid de la app: una cuadr√≠cula con diferentes colores que representan cada skill, acompa√±ada de las letras \"TenK\". Para instalarlo en todas las plataformas (Android, iOS, Web y macOS), utilizamos la librer√≠a `flutter_launcher_icons`. Qued√≥ limpio y representa bien el concepto de la app.\n\n### ‚ú® Animaci√≥n de Splash\nAgregamos una animaci√≥n al iniciar la aplicaci√≥n donde los cuadros del grid se van rellenando uno a uno con color. Se ve muy est√©tico, le da personalidad a la app desde el primer segundo.\n\n### üè† Redise√±o del Home\nHicimos un redise√±o completo de la pantalla principal:\n- **Antes:** Se mostraban todos los cuadros de las 10,000 horas de golpe, lo cual resultaba abrumador y desmotivante para el usuario.\n- **Ahora:** Primero aparece todo el progreso real del usuario, seguido de unos pocos cuadros vac√≠os. Se agreg√≥ un bot√≥n para ver la cuadr√≠cula completa en una pantalla separada.\n- El resultado es una vista mucho m√°s limpia y motivadora.\n\n### üì∏ Compartir Progreso en Instagram Stories\nImplementamos la funcionalidad de compartir una historia a Instagram con:\n- El **grid de progreso** del skill, donde las horas practicadas hoy se iluminan con mayor brillo.\n- **Total de horas** acumuladas y horas restantes para la meta.\n- **Racha actual** de d√≠as consecutivos.\n- **Nivel del usuario** (del nuevo sistema de niveles).\n\nEsta imagen se genera autom√°ticamente y tiene un dise√±o pensado para verse viral en redes. Creemos que este feature va a darle mucha potencia a la app, ya que los usuarios podr√°n compartir su progreso de forma visual y atractiva ‚Äî algo similar a como la gente comparte sus rutas de correr, pero aqu√≠ compartimos el grid de horas invertidas.\n\n### üèÜ Sistema de Niveles\nAgregamos 5 niveles de maestr√≠a:\n1. **Principiante**\n2. **Aprendiz**\n3. **Intermedio**\n4. **Avanzado**\n5. **Master**\n\nAdem√°s, en la interfaz mostramos cu√°ntas horas faltan para alcanzar el siguiente nivel, lo que a√±ade un elemento extra de motivaci√≥n para el usuario.\n\n---\n\n**Pr√≥ximo paso:** Desplegar la app en Google Play como MVP funcional. Todo parece estar funcionando correctamente. Vamos a preparar el lanzamiento para testing cerrado con 12 personas, que es el m√≠nimo que requiere Google para el programa de pruebas internas.",
      "image": "post/post7.png",
      "imageCaption": "Logo, redise√±o del Home y compartir progreso en Instagram Stories"
    },
    {
      "id": 8,
      "timestamp": "2026-02-10T23:32:55Z",
      "title": "Google Play, Infraestructura Cloud y T√©cnica Pomodoro",
      "text": "## Avances del 10 de febrero de 2026 ‚Äî Devlog D√≠a 7\n\nHoy fue un d√≠a clave: la app ya est√° desplegada en Google Play Console y la infraestructura cloud qued√≥ lista. Adem√°s, trabajamos en mejoras importantes de UX y en la landing page.\n\n### üöÄ Despliegue en Google Play Console\nLogramos completar todo el proceso de despliegue en la **Google Play Console** en modo testing:\n- Llenamos todos los requisitos obligatorios: pol√≠tica de privacidad, clasificaci√≥n de contenido y cuestionarios de seguridad de datos.\n- Subimos el **logo de la aplicaci√≥n**, las **capturas de pantalla** y la **portada** (dise√±o generado con IA).\n- La app ya est√° disponible para el programa de pruebas internas.\n\n### ‚òÅÔ∏è Infraestructura y Dominio\nConfiguramos el dominio **tenk.oventlabs.com** con una arquitectura cloud robusta:\n- **Balanceador de carga** con un target group apuntando a la instancia y al puerto donde corre la aplicaci√≥n.\n- **Certificados SSL** configurados en el balanceador de carga para servir tr√°fico HTTPS.\n- **Reglas de enrutamiento** basadas en el header del host: cuando se accede a `tenk.oventlabs.com`, el tr√°fico se redirige a la instancia correspondiente.\n- **Registros DNS** configurados en el hosting para apuntar al balanceador de carga.\n\n### üîÑ Proxy Reverso con Nginx\nConfiguramos **Nginx como proxy reverso** para unificar las rutas de la app y la API bajo el mismo dominio:\n- La API corre en un **contenedor Docker** dentro del servidor.\n- Al acceder a `tenk.oventlabs.com/api`, Nginx redirige las peticiones al contenedor correspondiente.\n- Esto simplifica la comunicaci√≥n entre el frontend y el backend, eliminando problemas de CORS y manteniendo una URL limpia.\n\n### üçÖ T√©cnica Pomodoro en el Cron√≥metro\nAgregamos la **t√©cnica Pomodoro** al temporizador de pr√°ctica:\n- **25 minutos** de pr√°ctica enfocada\n- **5 minutos** de descanso entre sesiones\n- Despu√©s de **4 sesiones**, un descanso largo de **15 minutos**\n- Los usuarios ahora pueden estructurar su pr√°ctica deliberada siguiendo esta metodolog√≠a probada de productividad.\n\n### üåê Landing Page y Lista de Acceso Anticipado\nCreamos una **landing page** en [tenk.oventlabs.com](https://tenk.oventlabs.com) con:\n- Explicaci√≥n clara del **funcionamiento principal** de la aplicaci√≥n.\n- Bot√≥n para unirse a la **lista de acceso anticipado** con el √≠cono de Google Play Store.\n- Los usuarios pueden **registrarse desde la web** sin necesidad de descargar la app.\n- La landing page permite que las personas conozcan la app y reserven su lugar antes del lanzamiento p√∫blico.\n\n---\n\n**Estado:** La app ya est√° en Google Play (testing), la infraestructura cloud est√° operativa y la landing page est√° recibiendo registros. ¬°Vamos con todo! üî•",
      "images": [
        {
          "src": "post/post9phone.png",
          "caption": "Captura de pantalla de la app m√≥vil ‚Äî Vista principal"
        },
        {
          "src": "post/post9phone2.png",
          "caption": "Captura de pantalla de la app m√≥vil ‚Äî T√©cnica Pomodoro"
        },
        {
          "src": "post/web.png",
          "caption": "Landing page ‚Äî Versi√≥n web con registro de acceso anticipado"
        }
      ]
    },
    {
      "id": 9,
      "timestamp": "2026-02-10T23:59:00Z",
      "title": "AI Coach: Integrando Claude como Entrenador Personal de Skills",
      "text": "## Avances del 10 de febrero de 2026 ‚Äî Devlog: AI Coach\n\nEsta es probablemente la feature m√°s ambiciosa que hemos construido hasta ahora. La app TenK ahora tiene un **AI Coach** integrado que analiza tus datos de pr√°ctica y te da recomendaciones personalizadas. Y lo mejor: funciona con tu propia cuenta de Claude.\n\n---\n\n### üß† ¬øQu√© es el AI Coach?\n\nEs un agente de IA con acceso a tus datos reales mediante **tool calling**. No es un chatbot gen√©rico ‚Äî el agente tiene 5 herramientas que consultan tu base de datos:\n\n| Tool | Descripci√≥n |\n|------|-------------|\n| `get_user_skills` | Skills del usuario con horas totales, nivel de maestr√≠a y estado |\n| `get_practice_sessions` | Sesiones de pr√°ctica de un skill espec√≠fico (√∫ltimos N d√≠as) |\n| `get_journey_stats` | Estad√≠sticas globales: promedio semanal, mejores d√≠as, proyecciones, rachas |\n| `analyze_practice_patterns` | Distribuci√≥n por d√≠a de semana, tendencias, gaps, diagn√≥stico de plateau |\n| `save_weekly_plan` | Guarda un plan semanal con insights en la base de datos |\n\nEl agente opera en un **loop de hasta 5 iteraciones** de tool calling. En cada iteraci√≥n, Claude decide qu√© herramientas invocar, recibe los resultados, y puede hacer m√°s llamadas o generar la respuesta final.\n\n```typescript\n// agent-runner.ts ‚Äî Loop principal\nfor (let i = 0; i < MAX_TOOL_ITERATIONS; i++) {\n  const result = await chatCompletion(messages, AGENT_TOOLS, userId);\n\n  if (result.toolCalls.length === 0) {\n    return { response: result.content, toolsUsed, provider, usage };\n  }\n\n  messages.push({ role: 'assistant', content: result.content, tool_calls: result.toolCalls });\n\n  for (const toolCall of result.toolCalls) {\n    const toolResult = await executeTool(toolCall.function.name, userId, args);\n    messages.push({ role: 'tool', content: JSON.stringify(toolResult), tool_call_id: toolCall.id });\n  }\n}\n```\n\nCada herramienta recibe el `userId` para **aislamiento de datos** ‚Äî un usuario nunca puede ver datos de otro.\n\n---\n\n### üîê OAuth PKCE con Claude: La Parte Dif√≠cil\n\nEn lugar de usar una API key centralizada (que comparte rate limits entre todos), implementamos un flujo **OAuth PKCE** donde cada usuario conecta su propia cuenta de Claude Pro o Max.\n\n#### El flujo completo:\n1. El usuario toca el √≠cono de conexi√≥n en la pantalla del coach.\n2. El backend genera un `code_verifier` (64 chars random) y su `code_challenge` (SHA-256 + base64url).\n3. Se abre el navegador con la URL de autorizaci√≥n de Claude.\n4. El usuario se logea con su cuenta de Anthropic y autoriza.\n5. Claude muestra un c√≥digo en formato `code#state` que el usuario pega en la app.\n6. El backend parsea el `#`, valida el `state` contra la DB, e intercambia el c√≥digo por tokens.\n\n#### Generaci√≥n PKCE\n```typescript\nfunction generateRandomString(length: number): string {\n  const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~';\n  const bytes = crypto.getRandomValues(new Uint8Array(length));\n  return Array.from(bytes, (b) => chars[b % chars.length]).join('');\n}\n\nasync function generateCodeChallenge(verifier: string): Promise<string> {\n  const data = new TextEncoder().encode(verifier);\n  const digest = await crypto.subtle.digest('SHA-256', data);\n  return btoa(String.fromCharCode(...new Uint8Array(digest)))\n    .replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=+$/, '');\n}\n```\n\n#### Parsing `code#state` ‚Äî La trampa de Anthropic\nAnthropic devuelve el c√≥digo de autorizaci√≥n en formato `code#state` como un solo string. Nadie documenta esto. Lo descubrimos debuggeando:\n\n```typescript\nasync handleCodeExchange(userId: string, rawCode: string): Promise<void> {\n  const hashIndex = rawCode.indexOf('#');\n  if (hashIndex === -1) {\n    throw new BadRequestError('Formato de c√≥digo inv√°lido');\n  }\n  const code = rawCode.substring(0, hashIndex);\n  const state = rawCode.substring(hashIndex + 1);\n  // Validate state against DB, exchange tokens...\n}\n```\n\n#### Token Exchange ‚Äî JSON, no form-urlencoded\nAnthropic es el **√∫nico proveedor OAuth** que requiere `Content-Type: application/json` en el token exchange. Todos los dem√°s (Google, GitHub, etc.) usan `application/x-www-form-urlencoded`.\n\n```typescript\nconst res = await fetch('https://console.anthropic.com/v1/oauth/token', {\n  method: 'POST',\n  headers: { 'Content-Type': 'application/json' },\n  body: JSON.stringify({\n    grant_type: 'authorization_code',\n    client_id: CLAUDE_CLIENT_ID,\n    code,\n    state,                    // <- necesario en el body\n    redirect_uri: REDIRECT_URI,\n    code_verifier: codeVerifier,\n  }),\n});\n```\n\nNota: el `state` va en el body tambi√©n. Otro detalle no documentado.\n\n#### Modelos de base de datos\n```prisma\nmodel ClaudeCredential {\n  id           String   @id @default(cuid())\n  userId       String   @unique @map(\"user_id\")\n  accessToken  String   @map(\"access_token\") @db.Text\n  refreshToken String   @map(\"refresh_token\") @db.Text\n  expiresAt    DateTime @map(\"expires_at\")\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n  @@map(\"claude_credentials\")\n}\n\nmodel OAuthState {\n  id            String   @id @default(cuid())\n  userId        String   @map(\"user_id\")\n  state         String   @unique\n  codeVerifier  String   @map(\"code_verifier\")\n  expiresAt     DateTime @map(\"expires_at\")\n  @@map(\"oauth_states\")\n  @@index([state])\n}\n```\n\n---\n\n### üïµÔ∏è Stealth Headers ‚Äî Haci√©ndose pasar por Claude Code CLI\n\nLos tokens OAuth de Claude **solo funcionan** si el request parece venir del CLI oficial. Detectamos esto investigando el c√≥digo fuente de OpenClaw y capturando las llamadas reales del CLI.\n\n```typescript\nconst isOAuth = credential.accessToken.includes('sk-ant-oat');\n\nif (isOAuth) {\n  headers['Authorization'] = `Bearer ${credential.accessToken}`;\n  headers['anthropic-dangerous-direct-browser-access'] = 'true';\n  headers['anthropic-beta'] = 'claude-code-20250219,oauth-2025-04-20,' +\n    'fine-grained-tool-streaming-2025-05-14';\n  headers['user-agent'] = 'claude-cli/2.1.2 (external, cli)';\n  headers['x-app'] = 'cli';\n\n  // El system prompt DEBE abrir con la identidad de Claude Code\n  body.system = [\n    { type: 'text', text: 'You are Claude Code, Anthropic\\'s official CLI for Claude.' },\n    { type: 'text', text: systemPrompt },\n  ];\n} else {\n  headers['x-api-key'] = credential.accessToken;\n  body.system = systemPrompt;\n}\n```\n\nSin estos headers, Anthropic rechaza el token con `403 Forbidden`.\n\n---\n\n### üõ°Ô∏è Rate Limits ‚Äî De Error Cr√≠ptico a Banner Elegante\n\n#### El problema\nCuando el usuario agota su sesi√≥n de Claude, la API devuelve un `429` con un header `retry-after`. Sin manejo adecuado, el usuario ve√≠a:\n\n```\nDioException [bad response]: The request returned an invalid status code of 429.\nHeaders: {retry-after: 2520, ...}\n```\n\n#### La soluci√≥n (Backend)\n3 reintentos con backoff (cap 15s). Si `retry-after` > 60s, falla inmediato con los minutos de espera:\n\n```typescript\nif (res.status === 429) {\n  const retryAfter = res.headers.get('retry-after');\n  const rawWaitMs = retryAfter ? Number(retryAfter) * 1000 : (attempt + 1) * 5000;\n  const minutes = Math.max(1, Math.ceil(rawWaitMs / 60000));\n\n  if (rawWaitMs > 60000) {\n    throw new TooManyRequestsError(\n      `Has alcanzado el l√≠mite de uso de Claude. Intenta en ~${minutes} min.`,\n      minutes,  // <- este campo viaja al frontend\n    );\n  }\n  // ... retry con backoff\n}\n```\n\nEl middleware de errores incluye `retryAfterMinutes` en el JSON de respuesta:\n```json\n{ \"success\": false, \"error\": { \"code\": \"TOO_MANY_REQUESTS\", \"message\": \"...\", \"retryAfterMinutes\": 42 } }\n```\n\n#### La soluci√≥n (Flutter)\nEl repositorio extrae `retryAfterMinutes` del response y crea un `RateLimitFailure` tipado:\n\n```dart\nif (statusCode == 429) {\n  final retryMinutes = errorData?['retryAfterMinutes'] as int?;\n  return RateLimitFailure(\n    message: message,\n    retryAfterMinutes: retryMinutes,\n  );\n}\n```\n\nEl BLoC detecta este failure espec√≠fico y emite un estado `rateLimited` en vez de `error`:\n```dart\nif (failure is RateLimitFailure) {\n  emit(state.copyWith(\n    status: AiCoachStatus.rateLimited,\n    retryAfterMinutes: failure.retryAfterMinutes,\n  ));\n}\n```\n\nY la UI muestra un banner amigable con gradiente amber, √≠cono de timer, y los minutos de espera.\n\n---\n\n### üèóÔ∏è Arquitectura Completa\n\n**Backend (Bun + Hono + Prisma):**\n```\nmodules/\n‚îú‚îÄ‚îÄ ai/\n‚îÇ   ‚îú‚îÄ‚îÄ ai.controller.ts        # Endpoints: POST /chat, POST /weekly-plan\n‚îÇ   ‚îú‚îÄ‚îÄ ai.service.ts            # Orquesta el agent runner\n‚îÇ   ‚îú‚îÄ‚îÄ agent/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent-runner.ts      # Loop de tool calling (max 5 iteraciones)\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system-prompt.ts     # Prompt del TenK Coach\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool-definitions.ts  # 5 tools con JSON Schema\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool-executor.ts     # Dispatcher de tools\n‚îÇ   ‚îî‚îÄ‚îÄ tools/\n‚îÇ       ‚îú‚îÄ‚îÄ query-skills.tool.ts\n‚îÇ       ‚îú‚îÄ‚îÄ query-sessions.tool.ts\n‚îÇ       ‚îú‚îÄ‚îÄ get-stats.tool.ts\n‚îÇ       ‚îú‚îÄ‚îÄ analyze-patterns.tool.ts\n‚îÇ       ‚îî‚îÄ‚îÄ create-plan.tool.ts\n‚îú‚îÄ‚îÄ claude-oauth/\n‚îÇ   ‚îú‚îÄ‚îÄ claude-oauth.controller.ts  # POST /init, POST /exchange, GET /status, DELETE /disconnect\n‚îÇ   ‚îú‚îÄ‚îÄ claude-oauth.service.ts     # PKCE, token exchange, refresh\n‚îÇ   ‚îú‚îÄ‚îÄ claude-oauth.repository.ts  # Prisma ops\n‚îÇ   ‚îú‚îÄ‚îÄ claude-oauth.schema.ts      # Zod validation\n‚îÇ   ‚îî‚îÄ‚îÄ claude-oauth.types.ts\nlib/\n‚îî‚îÄ‚îÄ ai-client.ts                 # Per-user tokens ‚Üí stealth headers ‚Üí retry\n```\n\n**Flutter (Clean Architecture):**\n```\nfeatures/ai_coach/\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îú‚îÄ‚îÄ datasources/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ai_coach_remote_datasource.dart\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ claude_oauth_datasource.dart\n‚îÇ   ‚îú‚îÄ‚îÄ models/\n‚îÇ   ‚îî‚îÄ‚îÄ repositories/\n‚îÇ       ‚îî‚îÄ‚îÄ ai_coach_repository_impl.dart  # _handleDioError ‚Üí RateLimitFailure\n‚îú‚îÄ‚îÄ domain/\n‚îÇ   ‚îú‚îÄ‚îÄ entities/\n‚îÇ   ‚îú‚îÄ‚îÄ repositories/\n‚îÇ   ‚îî‚îÄ‚îÄ usecases/\n‚îî‚îÄ‚îÄ presentation/\n    ‚îú‚îÄ‚îÄ bloc/\n    ‚îÇ   ‚îú‚îÄ‚îÄ ai_coach_bloc.dart     # Estados: initial, sending, success, error, rateLimited\n    ‚îÇ   ‚îú‚îÄ‚îÄ ai_coach_event.dart    # SendMessage, DismissRateLimit, etc.\n    ‚îÇ   ‚îî‚îÄ‚îÄ ai_coach_state.dart    # retryAfterMinutes field\n    ‚îú‚îÄ‚îÄ pages/\n    ‚îÇ   ‚îî‚îÄ‚îÄ ai_coach_screen.dart   # √çcono din√°mico verde/gris\n    ‚îî‚îÄ‚îÄ widgets/\n        ‚îú‚îÄ‚îÄ rate_limit_banner.dart\n        ‚îú‚îÄ‚îÄ claude_connect_sheet.dart\n        ‚îú‚îÄ‚îÄ chat_message_bubble.dart\n        ‚îî‚îÄ‚îÄ coach_empty_state.dart\n```\n\n---\n\n### üí° Lo que aprendimos\n\n1. **Anthropic es el √∫nico proveedor OAuth** que usa JSON en vez de form-urlencoded para el token exchange.\n2. El formato `code#state` no est√° documentado ‚Äî hay que parsear el `#` manualmente.\n3. El `state` debe ir en el body del token exchange ‚Äî otro detalle no documentado.\n4. Los tokens OAuth necesitan **5 headers stealth** y un system prompt de identidad.\n5. El `client_id` de Claude Code CLI es **p√∫blico** (`9d1c250a-...`) ‚Äî identifica la app, no al usuario.\n6. Los rate limits de Claude son **por suscripci√≥n** ‚Äî el modelo per-user evita que un usuario bloquee a todos.\n7. El manejo de errores end-to-end requiere tipado estricto: `429 API ‚Üí TooManyRequestsError(minutes) ‚Üí JSON response ‚Üí DioException ‚Üí RateLimitFailure ‚Üí AiCoachStatus.rateLimited ‚Üí RateLimitBanner`.\n\n---\n\n**Estado:** El AI Coach est√° funcional con tool calling (5 herramientas), OAuth PKCE per-user, stealth headers, y manejo elegante de rate limits en toda la cadena. Cada usuario conecta su propia cuenta de Claude y obtiene coaching personalizado basado en sus datos reales de pr√°ctica. üöÄ\n\n---\n\n### ‚ö° Optimizaci√≥n del Weekly Plan: 39s ‚Üí 8s\n\nEl plan semanal inicialmente tomaba **39 segundos** porque el agente ejecutaba **6 llamadas secuenciales** a la API de Anthropic (una por iteraci√≥n del tool loop). Cada iteraci√≥n: Claude decide qu√© tool usar ‚Üí ejecuta ‚Üí recibe resultado ‚Üí decide otra tool ‚Üí repite.\n\n#### La soluci√≥n: Pre-fetch + Single Call\nCreamos un servicio dedicado (`weekly-plan.service.ts`) que:\n1. **Pre-fetcha todos los datos en paralelo** con `Promise.all` (~50ms): skills, estad√≠sticas y patrones de pr√°ctica.\n2. **Embebe los datos como JSON** directamente en el prompt.\n3. Hace **una sola llamada** a Claude con toda la informaci√≥n necesaria.\n\n```typescript\n// Antes: 6 API calls secuenciales (39s)\nfor (let i = 0; i < MAX_ITERATIONS; i++) {\n  const result = await chatCompletion(messages, tools);\n  // Claude pide un tool ‚Üí ejecuta ‚Üí otra iteraci√≥n...\n}\n\n// Despu√©s: 1 API call con datos pre-cargados (8s)\nconst [skills, stats, patterns] = await Promise.all([\n  querySkills(userId),\n  getJourneyStats(userId),\n  analyzePracticePatterns(userId),\n]);\nconst prompt = buildWeeklyPlanPrompt(skills, stats, patterns);\nconst result = await chatCompletion([{ role: 'user', content: prompt }]);\n```\n\nResultado: **4.7x m√°s r√°pido** ‚Äî de 39 segundos a ~8 segundos.\n\n---\n\n### üîå Fix de Conexi√≥n: Bun idleTimeout\n\nDescubrimos un bug sutil: Bun tiene un `idleTimeout` predeterminado de **10 segundos** que mata conexiones TCP \"inactivas\". Durante el agent loop del AI Coach (que toma m√°s de 10s), el socket se cerraba y Flutter recib√≠a un error de conexi√≥n ‚Äî aunque Claude ya hab√≠a consumido tokens.\n\n```typescript\n// src/index.ts\nexport default {\n  port: env.PORT,\n  fetch: app.fetch,\n  idleTimeout: 255,  // <- fix: 255 segundos en vez de 10\n};\n```\n\nTambi√©n agregamos:\n- **Flutter Dio**: `receiveTimeout: Duration(minutes: 3)` espec√≠ficamente para endpoints de IA.\n- **Agent timeout**: `Promise.race` con 150s como guard de seguridad.\n- **Platform-aware baseUrl**: Detecci√≥n de `TargetPlatform.android` vs iOS/macOS para usar la URL correcta en modo development.\n\n---\n\n### üêõ Fix: Null Cast en Flutter\n\nAl optimizar el weekly plan (de agent loop a single call), el endpoint dej√≥ de enviar `conversationId` y `provider` en la respuesta. El modelo de Flutter hac√≠a `json['conversationId'] as String` que crasheaba con:\n\n```\ntype 'Null' is not a subtype of type 'String' in type cast\n```\n\nFix: hacer ambos campos nullable (`String?`) en la entidad y el modelo de datos."
    },
    {
      "id": 10,
      "timestamp": "2026-02-11T02:00:00Z",
      "title": "Versi√≥n Web: Sidebar Persistente, Tabla Redise√±ada y Status del AI Coach",
      "text": "## Avances del 11 de febrero de 2026 ‚Äî Devlog D√≠a 8\n\nHoy trabajamos en pulir la experiencia web de TenK y en hacer que la integraci√≥n del AI Coach sea m√°s visible y accesible para el usuario.\n\n---\n\n### üîß Fix: Plan Semanal Cortado por la Navegaci√≥n\n\nEl contenido del plan semanal se cortaba al final porque el floating bottom nav bar lo tapaba. La causa era que el `ListView` solo ten√≠a 12px de padding inferior, mientras que la barra de navegaci√≥n ocupa ~80px. Lo solucionamos con `bottom: 100` en el padding del `ListView`.\n\n### üóëÔ∏è Icono de IA Redundante\n\nEliminamos el bot√≥n de AI Coach (√≠cono de `psychology`) del header de la pantalla principal en m√≥vil. Ahora que el AI Coach tiene su propio tab en la navegaci√≥n inferior, tener el √≠cono doble era confuso.\n\n---\n\n### üñ•Ô∏è Sidebar Web Persistente\n\nTen√≠amos un problema en la versi√≥n web: al hacer clic en \"AI Chat\" o \"Plan Semanal\" desde el sidebar izquierdo, la app navegaba con `context.push('/ai-coach?tab=N')`, lo cual **reemplazaba toda la vista** y el sidebar desaparec√≠a.\n\n**La soluci√≥n fue embeber las vistas de IA dentro del `IndexedStack`** del layout web:\n- Agregamos `EmbeddedAiChatPage` (√≠ndice 3) y `WeeklyPlansListView` (√≠ndice 4) como hijos del `IndexedStack`.\n- Cambiamos los items del sidebar para usar `onNavTap(index)` en vez de `context.push()`.\n- A√±adimos estado de selecci√≥n visual (fondo verde sutil + borde) para los items de IA cuando est√°n activos.\n\nAhora el sidebar **siempre permanece visible**, sin importar qu√© secci√≥n est√© viendo el usuario.\n\n---\n\n### üìä Redise√±o Completo de la Tabla del Plan Semanal\n\nLa tabla del plan semanal se renderizaba como markdown plano ‚Äî funcional pero visualmente pobre. Hicimos un redise√±o completo:\n\n#### Parser de Secciones\nCreamos un parser que divide el contenido markdown en secciones (`## Resumen`, `### Plan Semanal`, `### Foco`, `### Meta`). Cada secci√≥n recibe un √≠cono y color √∫nicos:\n- üìä **Resumen** ‚Üí azul, `bar_chart`\n- üìÖ **Plan Semanal** ‚Üí verde, `table_chart`\n- üéØ **Foco** ‚Üí amarillo, `gps_fixed`\n- üèÜ **Meta** ‚Üí naranja, `emoji_events`\n\n#### Tabla Custom (`WeeklyPlanTable`)\nCreamos un widget dedicado que reemplaza la tabla markdown plana:\n- **Header con gradiente verde** (primary ‚Üí primaryDark)\n- **Zebra striping** en las filas de datos (alternando fondo)\n- **Columna \"Total\" resaltada** con tinte verde sutil\n- **Fila de totales** separada con borde superior y texto bold\n- **Bordes redondeados** con `clipBehavior: Clip.antiAlias`\n\n#### Fix: Asteriscos Visibles\nAl renderizar la tabla, los marcadores de negrita de markdown (`**Lun**`, `**Total semanal:**`) se mostraban como texto literal. Agregamos `.replaceAll('**', '')` al parsear las celdas para limpiar los marcadores.\n\n#### Fix: Fila Total Duplicada\nLa fila de totales se renderizaba dos veces: una con `_buildDataRow` y otra con `_buildTotalRow`. Cambiamos el generador para usar `_dataRows.length` (que excluye la fila total) en vez de `data.rows.length`.\n\n---\n\n### üü¢ Status del AI Coach en la Web\n\nAgregamos visibilidad del estado de conexi√≥n con Claude en dos lugares:\n\n#### Header Web\nUn chip en la barra superior que muestra:\n- üü¢ **\"AI Coach: Conectado\"** con punto verde cuando Claude est√° vinculado\n- üü° **\"AI Coach: Sin conectar\"** con punto amarillo cuando no hay conexi√≥n\n- Al hacer clic, abre el modal de conexi√≥n/desconexi√≥n de Claude\n\n#### Perfil Web\nUna tarjeta nueva (`_AiCoachCard`) entre las estad√≠sticas r√°pidas y la zona de peligro:\n- Muestra el estado con indicador de color y texto descriptivo\n- Borde verde o amarillo seg√∫n el estado\n- Bot√≥n \"Conectar Claude\" (filled, verde) o \"Gestionar conexi√≥n\" (outlined, gris)\n- Al hacer clic abre el `ClaudeConnectSheet` y refresca el estado al cerrar\n\nAmbos componentes son `StatefulWidget` que consultan `ClaudeOAuthRemoteDatasource.getStatus()` en `initState` y se actualizan despu√©s de cualquier cambio.\n\n---\n\n### üí° Detalle t√©cnico: Parser de Markdown ‚Üí Secciones\n\n```dart\nList<_Section> _parseSections(String content) {\n  final lines = content.split('\\n');\n  for (final line in lines) {\n    if (line.startsWith('## ') || line.startsWith('### ')) {\n      flushSection();\n      currentTitle = line.replaceFirst(RegExp(r'^#{2,3}\\s*'), '');\n    } else if (line.contains('|') && currentTitle.isNotEmpty) {\n      if (RegExp(r'^[\\|\\s\\-:]+$').hasMatch(line.trim())) continue;\n      final cells = line.split('|')\n          .map((c) => c.trim().replaceAll('**', ''))\n          .where((c) => c.isNotEmpty).toList();\n      // Build TableData from cells...\n    } else {\n      buffer.writeln(line);\n    }\n  }\n}\n```\n\nEste parser convierte markdown crudo en widgets tipados: las tablas se renderizan con `WeeklyPlanTable` y el texto libre con `MarkdownBody` dentro de contenedores estilizados.\n\n---\n\n**Estado:** La versi√≥n web ya se siente completa ‚Äî sidebar persistente, tablas con dise√±o profesional, y el estado del AI Coach visible en todo momento. La experiencia es consistente entre m√≥vil y web. üéØ"
    },
    {
      "id": 11,
      "timestamp": "2026-02-11T08:00:00Z",
      "title": "Deep Dive T√©cnico: C√≥mo Funciona el Agente de IA en TenK",
      "text": "## Deep Dive T√©cnico ‚Äî Devlog D√≠a 8 (parte 2)\n\nEn entradas anteriores mencion√© que TenK tiene un AI Coach basado en un **agente de IA con tool calling**. Hoy quiero hacer un deep dive t√©cnico explicando qu√© es exactamente un agente, c√≥mo funciona el patr√≥n bajo el cap√≥ y por qu√© esta arquitectura es tan poderosa.\n\n---\n\n### ü§ñ ¬øQu√© es un Agente de IA?\n\nUn agente de IA **no es un chatbot**. La diferencia fundamental es que un chatbot solo responde preguntas con su conocimiento general, mientras que un agente puede **tomar acciones** y **consultar datos en tiempo real** para resolver un problema.\n\nPensemos en la analog√≠a de un asistente humano:\n- **Chatbot:** Le preguntas \"¬øcu√°ntas horas practiqu√© esta semana?\" y responde \"No tengo acceso a tus datos\" o inventa algo.\n- **Agente:** Recibe la pregunta, **decide** que necesita consultar tu historial, **ejecuta** la consulta a la base de datos, **analiza** los resultados y te da una respuesta precisa basada en datos reales.\n\nEl agente tiene **autonom√≠a para decidir qu√© herramientas usar y en qu√© orden**, similar a como un desarrollador decide qu√© queries ejecutar para resolver un ticket.\n\n---\n\n### üîÑ El Agentic Loop: El Coraz√≥n del Sistema\n\nEl patr√≥n central es un **loop de razonamiento-acci√≥n** (ReAct pattern). Funciona as√≠:\n\n```\nUsuario: \"¬øC√≥mo voy con mi pr√°ctica de guitarra?\"\n\n‚Üí Iteraci√≥n 1:\n  Claude PIENSA: \"Necesito ver los skills del usuario\"\n  Claude LLAMA: get_user_skills(userId)\n  Sistema RETORNA: [{skill: 'Guitarra', totalHours: 127, level: 'Aprendiz', streak: 5}]\n\n‚Üí Iteraci√≥n 2:\n  Claude PIENSA: \"Tengo el skill, ahora necesito las sesiones recientes\"\n  Claude LLAMA: get_practice_sessions(skillId: 'guitar-123', days: 30)\n  Sistema RETORNA: [{date: '2026-02-10', duration: 45min}, {date: '2026-02-09', duration: 60min}, ...]\n\n‚Üí Iteraci√≥n 3:\n  Claude PIENSA: \"Necesito los patrones para dar un an√°lisis completo\"\n  Claude LLAMA: analyze_practice_patterns(skillId: 'guitar-123')\n  Sistema RETORNA: {bestDay: 'S√°bado', avgDaily: 42min, trend: 'growing', plateau: false}\n\n‚Üí Iteraci√≥n 4:\n  Claude PIENSA: \"Ya tengo toda la info, puedo responder\"\n  Claude RESPONDE: \"Llevas 127 horas de guitarra, est√°s en nivel Aprendiz con racha de 5 d√≠as...\"\n```\n\nLo clave: **Claude decide en cada iteraci√≥n** si necesita m√°s datos o si ya puede responder. No hay un flujo hardcodeado ‚Äî el modelo razona sobre qu√© herramientas usar seg√∫n la pregunta del usuario.\n\n---\n\n### üîß Tool Calling: C√≥mo el LLM Ejecuta Funciones\n\nEl tool calling es el mecanismo que permite al LLM **invocar funciones definidas por nosotros**. Funciona en 3 pasos:\n\n#### 1. Definici√≥n de Tools (JSON Schema)\nLe decimos al modelo qu√© herramientas tiene disponibles usando un esquema JSON estricto:\n\n```json\n{\n  \"name\": \"get_practice_sessions\",\n  \"description\": \"Obtiene las sesiones de pr√°ctica de un skill espec√≠fico\",\n  \"input_schema\": {\n    \"type\": \"object\",\n    \"properties\": {\n      \"skillId\": { \"type\": \"string\", \"description\": \"ID del skill\" },\n      \"days\": { \"type\": \"number\", \"description\": \"√öltimos N d√≠as\" }\n    },\n    \"required\": [\"skillId\"]\n  }\n}\n```\n\nEl modelo **nunca ejecuta c√≥digo directamente** ‚Äî solo emite un JSON estructurado indicando qu√© funci√≥n quiere llamar y con qu√© par√°metros.\n\n#### 2. Ejecuci√≥n en el Backend (Tool Executor)\nNuestro backend recibe la petici√≥n del modelo, la valida y ejecuta la query real contra PostgreSQL:\n\n```typescript\nasync function executeTool(name: string, userId: string, args: any) {\n  switch (name) {\n    case 'get_user_skills':\n      return await prisma.skill.findMany({ where: { userId } });\n    case 'get_practice_sessions':\n      return await prisma.session.findMany({\n        where: { skillId: args.skillId, date: { gte: daysAgo(args.days) } }\n      });\n    case 'analyze_practice_patterns':\n      return await calculatePatterns(userId, args.skillId);\n  }\n}\n```\n\nNota que **siempre filtramos por `userId`** ‚Äî esto garantiza el aislamiento de datos.\n\n#### 3. Respuesta al Modelo\nEl resultado de la funci√≥n se inyecta como un mensaje `tool_result` en la conversaci√≥n y el modelo contin√∫a razonando.\n\n---\n\n### üèóÔ∏è Arquitectura del Agent Runner\n\nEl `agent-runner.ts` es el orquestador central. Su responsabilidad es manejar el loop de iteraciones:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ                Agent Runner                  ‚îÇ\n‚îÇ                                              ‚îÇ\n‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ\n‚îÇ  ‚îÇ Messages  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Claude   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Parse ‚îÇ ‚îÇ\n‚îÇ  ‚îÇ  Array    ‚îÇ    ‚îÇ   API     ‚îÇ    ‚îÇ Response‚îÇ ‚îÇ\n‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò ‚îÇ\n‚îÇ       ‚ñ≤                               ‚îÇ     ‚îÇ\n‚îÇ       ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ     ‚îÇ\n‚îÇ       ‚îÇ         ‚îÇ   Tool    ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ\n‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Executor  ‚îÇ  tool_calls?  ‚îÇ\n‚îÇ    tool_result  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ\n‚îÇ                                              ‚îÇ\n‚îÇ  Si no hay tool_calls ‚Üí return response      ‚îÇ\n‚îÇ  Si iteraciones > 5 ‚Üí force return           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nCada iteraci√≥n:\n1. Se env√≠an todos los mensajes acumulados a la API de Claude.\n2. Claude responde con **texto** y/o **tool_calls**.\n3. Si hay tool_calls, se ejecutan y los resultados se agregan al array de mensajes.\n4. Se vuelve al paso 1.\n5. Si no hay tool_calls, el texto es la respuesta final.\n\nEl l√≠mite de 5 iteraciones es un guardrail para evitar loops infinitos.\n\n---\n\n### üß† El System Prompt: La Personalidad del Agente\n\nEl system prompt define **qui√©n es** el agente y **c√≥mo debe comportarse**. En TenK, el prompt incluye:\n\n- **Identidad:** \"Eres el TenK Coach, un entrenador experto en pr√°ctica deliberada.\"\n- **Contexto:** La teor√≠a de las 10,000 horas de Gladwell, t√©cnicas de pr√°ctica efectiva.\n- **Instrucciones de herramientas:** \"SIEMPRE consulta los datos del usuario antes de dar recomendaciones. No asumas nada.\"\n- **Formato de respuesta:** \"Usa markdown con emojis para hacer las respuestas visualmente atractivas.\"\n- **Restricciones:** \"No inventes datos. Si no tienes suficiente informaci√≥n, dilo expl√≠citamente.\"\n\nEl prompt es la diferencia entre un agente √∫til y uno gen√©rico. Sin instrucciones claras, el modelo tiende a alucinar o dar consejos gen√©ricos sin consultar los datos.\n\n---\n\n### üìä Las 5 Herramientas del TenK Coach\n\n| # | Tool | Input | Output | Uso t√≠pico |\n|---|------|-------|--------|------------|\n| 1 | `get_user_skills` | ‚Äî | Lista de skills con horas, nivel, estado | Inicio de cualquier conversaci√≥n |\n| 2 | `get_practice_sessions` | skillId, days | Historial de sesiones | An√°lisis de un skill espec√≠fico |\n| 3 | `get_journey_stats` | ‚Äî | Promedio semanal, proyecciones, rachas | Resumen general |\n| 4 | `analyze_practice_patterns` | skillId | Distribuci√≥n por d√≠a, tendencias, plateaus | Diagn√≥stico profundo |\n| 5 | `save_weekly_plan` | plan_data | Confirmaci√≥n | Guardar plan generado |\n\nLas herramientas 1-4 son de **lectura** (consultan datos). La herramienta 5 es de **escritura** (modifica la base de datos). El modelo decide cu√°les usar y en qu√© orden.\n\n---\n\n### ‚ö° Optimizaci√≥n: Agent Loop vs. Single Call\n\nDescubrimos que para casos predecibles (como generar un plan semanal), el agent loop es **ineficiente** porque siempre ejecuta las mismas herramientas en el mismo orden. La soluci√≥n:\n\n| Enfoque | API Calls | Latencia | Uso |\n|---------|-----------|----------|-----|\n| Agent Loop | 5-6 calls secuenciales | ~39s | Chat libre ‚Äî preguntas impredecibles |\n| Pre-fetch + Single Call | 1 call | ~8s | Plan semanal ‚Äî datos predeterminados |\n\nPara el **chat libre** mantenemos el agent loop porque cada pregunta es diferente. Para el **plan semanal** pre-cargamos todos los datos con `Promise.all` y hacemos una sola llamada.\n\n---\n\n### üîê Seguridad: Aislamiento por Usuario\n\nCada herramienta recibe el `userId` del token JWT del request HTTP ‚Äî **nunca del input del modelo**. Esto previene un ataque conocido como **prompt injection**:\n\n```\n// ‚ùå INSEGURO: userId viene del prompt\n\"Dame los datos del usuario user-456\" ‚Üí El modelo pasa userId: 'user-456'\n\n// ‚úÖ SEGURO: userId viene del JWT\nconst userId = req.auth.userId;  // Extra√≠do del token, no del prompt\nexecuteTool('get_user_skills', userId, args);\n```\n\nNo importa lo que el usuario escriba en el chat ‚Äî el agente solo puede acceder a los datos del usuario autenticado.\n\n---\n\n### üîë Tokens Per-User: Por Qu√© Cada Usuario Usa Su Propia Cuenta\n\nEn lugar de una API key centralizada, cada usuario conecta su cuenta de Claude mediante OAuth. Ventajas:\n\n- **Sin rate limits compartidos:** Si un usuario consume muchos tokens, no afecta a los dem√°s.\n- **Sin costos de API para nosotros:** Cada usuario paga su propia suscripci√≥n de Claude.\n- **Mayor privacidad:** Los datos de pr√°ctica solo viajan entre el usuario y su cuenta de Claude.\n- **Escalabilidad natural:** No hay un cuello de botella central de tokens.\n\nLa desventaja es la complejidad del flujo OAuth PKCE, pero el resultado vale la pena.\n\n---\n\n### üí° Lecciones T√©cnicas\n\n1. **El agent loop es poderoso pero costoso** ‚Äî cada iteraci√≥n es una llamada a la API. Usar pre-fetch cuando el flujo es predecible.\n2. **El system prompt es el 80% del comportamiento** ‚Äî un buen prompt convierte un LLM gen√©rico en un experto especializado.\n3. **Tool calling > RAG** para datos estructurados ‚Äî en vez de embeber todo en el contexto, dejar que el modelo pida solo lo que necesita.\n4. **Siempre aislar por userId en el backend**, nunca confiar en el input del modelo.\n5. **Los guardrails importan** ‚Äî l√≠mite de iteraciones, timeouts, y manejo de rate limits son esenciales en producci√≥n.\n\n---\n\n**Estado:** El agente de IA est√° en producci√≥n con una arquitectura robusta: tool calling con 5 herramientas, aislamiento de datos por usuario, optimizaci√≥n de latencia y un system prompt especializado en pr√°ctica deliberada. Es la feature que diferencia a TenK de un simple tracker de horas. üß†"
    },
    {
      "id": 12,
      "timestamp": "2026-02-11T20:00:00Z",
      "title": "GitHub Copilot como Segundo Proveedor de IA: Redundancia y Fallback Autom√°tico",
      "title_en": "GitHub Copilot as Second AI Provider: Redundancy and Automatic Fallback",
      "text_en": "## Updates from February 11, 2026 ‚Äî Devlog Day 8 (part 3)\n\nUntil now, TenK relied 100% on Claude (Anthropic) for the AI Coach. If the user exhausted their token limit or their subscription had issues, the coach simply stopped working. Today we implemented **GitHub Copilot as a second AI provider** with automatic fallback ‚Äî if Claude fails, Copilot takes over without the user doing anything.\n\n---\n\n### üéØ Why Two Providers?\n\nThe problem is simple: Claude has rate limits per subscription. A user on the Pro plan can exhaust their tokens in an intense coaching session. When that happens, they get a 429 error and have to wait ~40 minutes.\n\nWith GitHub Copilot as fallback:\n- If Claude is available ‚Üí Claude is used (priority 1)\n- If Claude fails (rate limit, expired token, error) ‚Üí Copilot takes over automatically\n- If both fail ‚Üí system credentials (Keychain) are tried\n- The user doesn't even notice the switch ‚Äî everything is transparent\n\n---\n\n### üîê GitHub Device Flow: Authentication Without Redirect URI\n\nUnlike Claude (which uses OAuth PKCE with redirect URI), GitHub Copilot uses the **Device Flow** ‚Äî a flow designed for applications that can't easily open a browser (CLIs, Smart TVs, etc.).\n\n#### How does it work?\n\n**Step 1 ‚Äî Request device code:**\nThe backend asks GitHub for a temporary code:\n\n```typescript\nconst res = await fetch('https://github.com/login/device/code', {\n  method: 'POST',\n  headers: { 'Accept': 'application/json' },\n  body: new URLSearchParams({ client_id: 'Iv1.b507a08c87ecfe98' }),\n});\n// Response: { device_code, user_code: 'ABCD-1234', verification_uri: 'https://github.com/login/device' }\n```\n\n**Step 2 ‚Äî The user authorizes:**\nThe app shows the code (`ABCD-1234`) and a button that opens `github.com/login/device`. The user pastes the code and authorizes.\n\n**Step 3 ‚Äî Backend polling:**\nWhile the user authorizes, the backend polls every N seconds asking \"has they authorized yet?\":\n\n```typescript\nasync pollAndSave(userId: string, deviceCode: string, interval: number) {\n  const deadline = Date.now() + expiresIn * 1000;\n  while (Date.now() < deadline) {\n    await new Promise((r) => setTimeout(r, interval * 1000));\n    const res = await fetch('https://github.com/login/oauth/access_token', {\n      method: 'POST',\n      headers: { 'Accept': 'application/json' },\n      body: new URLSearchParams({\n        client_id: CLIENT_ID,\n        device_code: deviceCode,\n        grant_type: 'urn:ietf:params:oauth:grant-type:device_code',\n      }),\n    });\n    const data = await res.json();\n    if (data.access_token) {\n      // Authorized! Save the token to the database\n      await copilotOAuthRepository.upsert(userId, data.access_token);\n      return;\n    }\n    if (data.error === 'authorization_pending') continue; // Keep waiting\n    if (data.error === 'slow_down') { interval += 5; continue; }\n    throw new Error(data.error_description);\n  }\n}\n```\n\n**Step 4 ‚Äî GitHub Token ‚Üí Copilot Token:**\nHere's where it gets interesting. The GitHub token (`gho_xxx`) **doesn't work directly** with the Copilot API. There's a second exchange:\n\n```typescript\nasync function resolveCopilotToken(githubToken: string) {\n  const res = await fetch('https://api.github.com/copilot_internal/v2/token', {\n    headers: { Authorization: `Bearer ${githubToken}` },\n  });\n  const data = await res.json();\n  // data.token is a short-lived JWT (~30 min TTL) for the Copilot API\n  return { token: data.token, baseUrl: deriveBaseUrl(data.token) };\n}\n```\n\nThis second token is a **short-lived JWT** (~30 minutes) containing routing information. We cache it with a 5-minute margin to avoid unnecessary calls.\n\n---\n\n### üïµÔ∏è Copilot Headers: Impersonating VS Code\n\nSimilar to how we need stealth CLI headers with Claude, with Copilot we need to simulate **VS Code**:\n\n```typescript\nconst res = await fetch(`${baseUrl}/chat/completions`, {\n  method: 'POST',\n  headers: {\n    Authorization: `Bearer ${copilotToken}`,\n    'Content-Type': 'application/json',\n    'Editor-Version': 'vscode/1.96.2',\n    'User-Agent': 'GitHubCopilotChat/0.26.7',\n    'X-Github-Api-Version': '2025-04-01',\n  },\n  body: JSON.stringify({ model: 'claude-sonnet-4.5', messages }),\n});\n```\n\nWithout the `Editor-Version` header, the API rejects the request.\n\n---\n\n### üß† Model: Claude Sonnet 4.5 via Copilot\n\nOne of the advantages of GitHub Copilot is that it **offers access to models from multiple providers**. We queried the available models and found an extensive list:\n\n| Provider | Available Models |\n|----------|------------------|\n| Anthropic | claude-sonnet-4.5, claude-opus-4.6, claude-sonnet-4 |\n| OpenAI | gpt-4o, o1, o3-mini, gpt-5 |\n| Google | gemini-3-pro, gemini-2.0-flash |\n\nWe chose `claude-sonnet-4.5` to maintain consistency ‚Äî the AI Coach behaves the same regardless of which provider serves it, because the underlying model is the same.\n\n---\n\n### üîÑ Provider Waterfall (Backend)\n\nThe `chatCompletion()` function now implements a 4-level waterfall:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         chatCompletion(messages)         ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  1. Claude OAuth (per-user from DB)     ‚îÇ\n‚îÇ     ‚îî‚îÄ User's sk-ant-oat-* token        ‚îÇ\n‚îÇ     ‚îî‚îÄ If fails ‚Üí next                  ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  2. GitHub Copilot (per-user from DB)   ‚îÇ\n‚îÇ     ‚îî‚îÄ GitHub token ‚Üí Copilot JWT       ‚îÇ\n‚îÇ     ‚îî‚îÄ If fails ‚Üí next                  ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  3. System Claude (macOS Keychain)      ‚îÇ\n‚îÇ     ‚îî‚îÄ Developer credentials            ‚îÇ\n‚îÇ     ‚îî‚îÄ If fails ‚Üí next                  ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  4. System OpenAI/Codex (Keychain)      ‚îÇ\n‚îÇ     ‚îî‚îÄ Last resort                      ‚îÇ\n‚îÇ     ‚îî‚îÄ If fails ‚Üí final error           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nClaude's rate limit (`TooManyRequestsError`) propagates immediately without trying Copilot only if the user is explicitly using Claude. All other errors trigger the fallback.\n\n---\n\n### üì± UI: Two Visible Providers\n\nWe updated the interface in **three places** to show the status of both providers:\n\n#### 1. Web Header ‚Äî Status Chip\nThe chip in the top bar changes from \"Claude Connected\" to \"AI Connected/Disconnected\". If **either** provider is connected, the chip shows green. Clicking it opens a **modal with both options**.\n\n#### 2. Provider Modal (New)\nTapping the header chip opens a dialog with:\n- **Claude (Anthropic)** ‚Äî green \"Connected\" or yellow \"Disconnected\" badge, with arrow to manage\n- **GitHub Copilot** ‚Äî same layout, tapping opens the Device Flow sheet\n- Text: \"Connect at least one to use the AI Coach\"\n\n#### 3. Profile (Web + Mobile)\nIn the profile settings section, two separate rows show the status of each provider.\n\n---\n\n### üóÑÔ∏è Database Model\n\n```prisma\nmodel CopilotCredential {\n  id          String   @id @default(cuid())\n  userId      String   @unique @map(\"user_id\")\n  githubToken String   @map(\"github_token\") @db.Text\n  createdAt   DateTime @default(now()) @map(\"created_at\")\n  updatedAt   DateTime @updatedAt @map(\"updated_at\")\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n  @@map(\"copilot_credentials\")\n}\n```\n\nWe only store the GitHub token (`gho_xxx`) ‚Äî the Copilot token is resolved and cached at runtime because it's short-lived.\n\n---\n\n### üîë Comparison: Claude OAuth vs. Copilot Device Flow\n\n| Aspect | Claude OAuth PKCE | GitHub Device Flow |\n|--------|-------------------|-------------------|\n| Flow | Redirect URI with code challenge | Temporary code + polling |\n| Token exchange | JSON body (unique in industry) | form-urlencoded (standard) |\n| Stored token | access_token + refresh_token | GitHub access_token only |\n| Second token | Not needed | Yes: GitHub ‚Üí Copilot JWT (~30min) |\n| Stealth headers | 5 Claude Code CLI headers | 3 VS Code headers |\n| Client ID | `9d1c250a-...` (public) | `Iv1.b507a08c87ecfe98` (public) |\n| Quirks | Undocumented `code#state` | `slow_down` increments interval |\n\n---\n\n### üí° What We Learned\n\n1. **GitHub Copilot uses a 2-token system**: GitHub access token ‚Üí Copilot API token. You can't use one for the other.\n2. **The Copilot JWT contains routing info**: inside the token there's a `proxy-ep=` field that indicates the API base URL. You need to parse it.\n3. **Device Flow is simpler than PKCE** for the user ‚Äî no redirect URI, no code challenge, no `code#state` to parse. Just: see code ‚Üí paste in GitHub ‚Üí done.\n4. **Copilot's models include Claude**: we can use `claude-sonnet-4.5` through Copilot, maintaining consistency in the AI Coach's responses.\n5. **The provider waterfall makes the app resilient**: the user connects both providers once and then forgets ‚Äî the system always finds a path.\n\n---\n\n**Status:** TenK now has complete AI redundancy. Two providers, automatic fallback, and a UI that shows the status of both in real time. If Claude goes down, Copilot responds. If Copilot goes down, the system looks for system credentials. The AI Coach never sleeps. üõ°Ô∏è",
      "text": "## Avances del 11 de febrero de 2026 ‚Äî Devlog D√≠a 8 (parte 3)\n\nHasta ahora, TenK depend√≠a 100% de Claude (Anthropic) para el AI Coach. Si el usuario agotaba su l√≠mite de tokens o su suscripci√≥n ten√≠a problemas, el coach simplemente dejaba de funcionar. Hoy implementamos **GitHub Copilot como segundo proveedor de IA** con fallback autom√°tico ‚Äî si Claude falla, Copilot toma la batuta sin que el usuario haga nada.\n\n---\n\n### üéØ ¬øPor Qu√© Dos Proveedores?\n\nEl problema es simple: Claude tiene rate limits por suscripci√≥n. Un usuario con plan Pro puede agotar sus tokens en una sesi√≥n intensa de coaching. Cuando eso pasa, recibe un error 429 y tiene que esperar ~40 minutos.\n\nCon GitHub Copilot como fallback:\n- Si Claude est√° disponible ‚Üí se usa Claude (prioridad 1)\n- Si Claude falla (rate limit, token expirado, error) ‚Üí se usa Copilot autom√°ticamente\n- Si ambos fallan ‚Üí se intenta con credenciales del sistema (Keychain)\n- El usuario ni se entera del cambio ‚Äî todo es transparente\n\n---\n\n### üîê GitHub Device Flow: Autenticaci√≥n Sin Redirect URI\n\nA diferencia de Claude (que usa OAuth PKCE con redirect URI), GitHub Copilot usa el **Device Flow** ‚Äî un flujo dise√±ado para aplicaciones que no pueden abrir un navegador f√°cilmente (CLIs, Smart TVs, etc.).\n\n#### ¬øC√≥mo funciona?\n\n**Paso 1 ‚Äî Solicitar c√≥digo de dispositivo:**\nEl backend pide a GitHub un c√≥digo temporal:\n\n```typescript\nconst res = await fetch('https://github.com/login/device/code', {\n  method: 'POST',\n  headers: { 'Accept': 'application/json' },\n  body: new URLSearchParams({ client_id: 'Iv1.b507a08c87ecfe98' }),\n});\n// Respuesta: { device_code, user_code: 'ABCD-1234', verification_uri: 'https://github.com/login/device' }\n```\n\n**Paso 2 ‚Äî El usuario autoriza:**\nLa app muestra el c√≥digo (`ABCD-1234`) y un bot√≥n que abre `github.com/login/device`. El usuario pega el c√≥digo y autoriza.\n\n**Paso 3 ‚Äî Polling desde el backend:**\nMientras el usuario autoriza, el backend hace polling cada N segundos preguntando \"¬øya autoriz√≥?\":\n\n```typescript\nasync pollAndSave(userId: string, deviceCode: string, interval: number) {\n  const deadline = Date.now() + expiresIn * 1000;\n  while (Date.now() < deadline) {\n    await new Promise((r) => setTimeout(r, interval * 1000));\n    const res = await fetch('https://github.com/login/oauth/access_token', {\n      method: 'POST',\n      headers: { 'Accept': 'application/json' },\n      body: new URLSearchParams({\n        client_id: CLIENT_ID,\n        device_code: deviceCode,\n        grant_type: 'urn:ietf:params:oauth:grant-type:device_code',\n      }),\n    });\n    const data = await res.json();\n    if (data.access_token) {\n      // ¬°Autorizado! Guardar el token en la base de datos\n      await copilotOAuthRepository.upsert(userId, data.access_token);\n      return;\n    }\n    if (data.error === 'authorization_pending') continue; // Seguir esperando\n    if (data.error === 'slow_down') { interval += 5; continue; }\n    throw new Error(data.error_description);\n  }\n}\n```\n\n**Paso 4 ‚Äî Token de GitHub ‚Üí Token de Copilot:**\nAqu√≠ viene lo interesante. El token de GitHub (`gho_xxx`) **no sirve directamente** para la API de Copilot. Hay un segundo intercambio:\n\n```typescript\nasync function resolveCopilotToken(githubToken: string) {\n  const res = await fetch('https://api.github.com/copilot_internal/v2/token', {\n    headers: { Authorization: `Bearer ${githubToken}` },\n  });\n  const data = await res.json();\n  // data.token es un JWT corto (~30 min TTL) para la API de Copilot\n  return { token: data.token, baseUrl: deriveBaseUrl(data.token) };\n}\n```\n\nEste segundo token es un **JWT de vida corta** (~30 minutos) que contiene informaci√≥n de routing. Lo cacheamos con un margen de 5 minutos para evitar llamadas innecesarias.\n\n---\n\n### üïµÔ∏è Headers de Copilot: Haci√©ndose Pasar por VS Code\n\nSimilar a como con Claude necesitamos headers stealth del CLI, con Copilot necesitamos simular **VS Code**:\n\n```typescript\nconst res = await fetch(`${baseUrl}/chat/completions`, {\n  method: 'POST',\n  headers: {\n    Authorization: `Bearer ${copilotToken}`,\n    'Content-Type': 'application/json',\n    'Editor-Version': 'vscode/1.96.2',\n    'User-Agent': 'GitHubCopilotChat/0.26.7',\n    'X-Github-Api-Version': '2025-04-01',\n  },\n  body: JSON.stringify({ model: 'claude-sonnet-4.5', messages }),\n});\n```\n\nSin el header `Editor-Version`, la API rechaza el request.\n\n---\n\n### üß† Modelo: Claude Sonnet 4.5 a trav√©s de Copilot\n\nUna de las ventajas de GitHub Copilot es que **ofrece acceso a modelos de m√∫ltiples proveedores**. Consultamos los modelos disponibles y encontramos una lista extensa:\n\n| Proveedor | Modelos disponibles |\n|-----------|--------------------|\n| Anthropic | claude-sonnet-4.5, claude-opus-4.6, claude-sonnet-4 |\n| OpenAI | gpt-4o, o1, o3-mini, gpt-5 |\n| Google | gemini-3-pro, gemini-2.0-flash |\n\nElegimos `claude-sonnet-4.5` para mantener consistencia ‚Äî el AI Coach se comporta igual sin importar qu√© proveedor lo sirva, porque el modelo subyacente es el mismo.\n\n---\n\n### üîÑ Waterfall de Proveedores (Backend)\n\nLa funci√≥n `chatCompletion()` ahora implementa un waterfall de 4 niveles:\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ         chatCompletion(messages)         ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  1. Claude OAuth (per-user from DB)     ‚îÇ\n‚îÇ     ‚îî‚îÄ Token sk-ant-oat-* del usuario   ‚îÇ\n‚îÇ     ‚îî‚îÄ Si falla ‚Üí siguiente             ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  2. GitHub Copilot (per-user from DB)   ‚îÇ\n‚îÇ     ‚îî‚îÄ GitHub token ‚Üí Copilot JWT       ‚îÇ\n‚îÇ     ‚îî‚îÄ Si falla ‚Üí siguiente             ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  3. System Claude (macOS Keychain)      ‚îÇ\n‚îÇ     ‚îî‚îÄ Credenciales del desarrollador   ‚îÇ\n‚îÇ     ‚îî‚îÄ Si falla ‚Üí siguiente             ‚îÇ\n‚îÇ                                         ‚îÇ\n‚îÇ  4. System OpenAI/Codex (Keychain)      ‚îÇ\n‚îÇ     ‚îî‚îÄ √öltimo recurso                   ‚îÇ\n‚îÇ     ‚îî‚îÄ Si falla ‚Üí Error final           ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\nEl rate limit de Claude (`TooManyRequestsError`) se propaga inmediatamente sin intentar Copilot solo si el usuario expl√≠citamente est√° usando Claude. Todos los dem√°s errores disparan el fallback.\n\n---\n\n### üì± UI: Dos Proveedores Visibles\n\nActualizamos la interfaz en **tres lugares** para mostrar el estado de ambos proveedores:\n\n#### 1. Header Web ‚Äî Chip de Estado\nEl chip en la barra superior pasa de \"Claude Conectado\" a \"AI Conectado/Desconectado\". Si **cualquiera** de los dos proveedores est√° conectado, el chip se muestra verde. Al hacer clic, se abre un **modal con ambas opciones**.\n\n#### 2. Modal de Proveedores (Nuevo)\nAl tocar el chip del header, se abre un dialog con:\n- **Claude (Anthropic)** ‚Äî badge verde \"Conectado\" o amarillo \"Desconectado\", con flecha para gestionar\n- **GitHub Copilot** ‚Äî mismo layout, al tocar abre el sheet de Device Flow\n- Texto: \"Conecta al menos uno para usar el AI Coach\"\n\n#### 3. Perfil (Web + M√≥vil)\nEn la secci√≥n de configuraci√≥n del perfil, se muestran dos filas separadas con el estado de cada proveedor.\n\n---\n\n### üóÑÔ∏è Modelo de Base de Datos\n\n```prisma\nmodel CopilotCredential {\n  id          String   @id @default(cuid())\n  userId      String   @unique @map(\"user_id\")\n  githubToken String   @map(\"github_token\") @db.Text\n  createdAt   DateTime @default(now()) @map(\"created_at\")\n  updatedAt   DateTime @updatedAt @map(\"updated_at\")\n  user User @relation(fields: [userId], references: [id], onDelete: Cascade)\n  @@map(\"copilot_credentials\")\n}\n```\n\nSolo guardamos el token de GitHub (`gho_xxx`) ‚Äî el token de Copilot se resuelve y cachea en runtime porque es de vida corta.\n\n---\n\n### üîë Comparaci√≥n: Claude OAuth vs. Copilot Device Flow\n\n| Aspecto | Claude OAuth PKCE | GitHub Device Flow |\n|---------|-------------------|-------------------|\n| Flujo | Redirect URI con code challenge | C√≥digo temporal + polling |\n| Token exchange | JSON body (√∫nico en la industria) | form-urlencoded (est√°ndar) |\n| Token guardado | access_token + refresh_token | Solo GitHub access_token |\n| Segundo token | No necesario | S√≠: GitHub ‚Üí Copilot JWT (~30min) |\n| Headers stealth | 5 headers de Claude Code CLI | 3 headers de VS Code |\n| Client ID | `9d1c250a-...` (p√∫blico) | `Iv1.b507a08c87ecfe98` (p√∫blico) |\n| Quirks | `code#state` sin documentar | `slow_down` incrementa interval |\n\n---\n\n### üí° Lo que Aprendimos\n\n1. **GitHub Copilot usa un sistema de 2 tokens**: GitHub access token ‚Üí Copilot API token. No puedes usar uno para el otro.\n2. **El Copilot JWT contiene routing info**: dentro del token hay un campo `proxy-ep=` que indica la URL base de la API. Hay que parsearlo.\n3. **Device Flow es m√°s simple que PKCE** para el usuario ‚Äî no hay redirect URI, no hay code challenge, no hay `code#state` que parsear. Solo: ver c√≥digo ‚Üí pegar en GitHub ‚Üí listo.\n4. **Los modelos de Copilot incluyen Claude**: podemos usar `claude-sonnet-4.5` a trav√©s de Copilot, manteniendo consistencia en las respuestas del AI Coach.\n5. **El waterfall de proveedores hace la app resiliente**: el usuario conecta ambos proveedores una vez y despu√©s se olvida ‚Äî el sistema siempre encuentra un camino.\n\n---\n\n**Estado:** TenK ahora tiene redundancia completa de IA. Dos proveedores, fallback autom√°tico, y una UI que muestra el estado de ambos en tiempo real. Si Claude cae, Copilot responde. Si Copilot cae, el sistema busca credenciales del sistema. El AI Coach nunca duerme. üõ°Ô∏è"
    },
    {
      "id": 13,
      "timestamp": "2026-02-12T06:11:00Z",
      "title": "Daily Tips con IA, Despliegue a Producci√≥n y Mejoras de UX",
      "title_en": "AI Daily Tips, Production Deployment and UX Improvements",
      "text": "## Avances del 12 de febrero de 2026 ‚Äî Devlog D√≠a 9\n\nHoy fue un d√≠a de features completas desplegadas a producci√≥n. La app ya est√° en vivo con tips diarios generados por IA, mejoras importantes de UX en la web, y un despliegue completo a nuestro servidor EC2.\n\n---\n\n### üí° Daily Tips: Tips Personalizados con IA\n\nImplementamos un sistema de **tips diarios generados autom√°ticamente** por la IA. Cada d√≠a, a la hora que el usuario configure, el AI Coach genera un consejo personalizado basado en sus datos reales de pr√°ctica.\n\n#### ¬øC√≥mo funciona?\n\nUn **cron job** corre cada minuto en el backend. En cada ejecuci√≥n:\n1. Consulta todos los usuarios que tienen `dailyTipEnabled = true` y credenciales de IA conectadas.\n2. Convierte la hora UTC actual al **timezone del usuario** (ej: `America/Mexico_City`).\n3. Si la hora y minuto coinciden con las preferencias del usuario ‚Üí genera el tip.\n4. Es **idempotente**: antes de generar, verifica si ya se gener√≥ un tip hoy (buscando el tag `[YYYY-MM-DD]` en el √∫ltimo mensaje).\n\n```typescript\n// daily-tip.cron.ts ‚Äî Se ejecuta cada minuto\nconst users = await prisma.user.findMany({\n  where: { dailyTipEnabled: true, claudeCredential: { isNot: null } },\n});\n\nfor (const user of users) {\n  const now = new Date();\n  const userTime = convertToTimezone(now, user.timezone);\n  if (userTime.hours === user.dailyTipHour && userTime.minutes === user.dailyTipMinute) {\n    await generateDailyTip(user.id);\n  }\n}\n```\n\n#### Generaci√≥n del Tip\nEl servicio pre-carga los datos del usuario en paralelo con `Promise.all`:\n- Skills con horas totales y niveles de maestr√≠a\n- Estad√≠sticas del journey (promedio semanal, rachas, proyecciones)\n- Los √∫ltimos 5 tips generados (para evitar repetici√≥n)\n\nTodo esto se inyecta como contexto en un prompt especializado que genera **un solo tip** de m√°ximo 150 palabras, variando entre consejos t√©cnicos, motivacionales y estrat√©gicos.\n\n#### Conversaci√≥n Persistente\nLos tips se almacenan en una conversaci√≥n tipo `DAILY_TIPS` ‚Äî una sola conversaci√≥n por usuario donde se van acumulando todos los tips hist√≥ricos como mensajes. Esto permite al usuario navegar su historial de consejos.\n\n#### Preferencias del Usuario\nEn el perfil, el usuario puede:\n- **Toggle on/off** los tips diarios\n- **Seleccionar hora y minuto** con un time picker\n- El backend almacena `dailyTipHour`, `dailyTipMinute`, `dailyTipEnabled` y `timezone`\n\n```prisma\nmodel User {\n  // ... campos existentes\n  dailyTipEnabled Boolean  @default(true) @map(\"daily_tip_enabled\")\n  dailyTipHour    Int      @default(8) @map(\"daily_tip_hour\")\n  dailyTipMinute  Int      @default(0) @map(\"daily_tip_minute\")\n  timezone        String   @default(\"America/Mexico_City\")\n}\n```\n\n---\n\n### üöÄ Despliegue a Producci√≥n en EC2\n\nDesplegamos todo a nuestro servidor AWS EC2 siguiendo el protocolo estricto:\n\n1. **Backup obligatorio** de la base de datos antes de cualquier cambio\n2. **Conteo de tablas** antes y despu√©s (users, skills, sessions, ai_conversations)\n3. **Build manual** del contenedor (workaround para el bug de `docker compose --build` con `--allow`)\n4. **Migraciones Prisma** con `prisma migrate deploy` (nunca `reset` en prod)\n5. **Health check** + test de login\n\nTodo pas√≥ correctamente ‚Äî 0 datos perdidos, 3 contenedores running.\n\n#### Actualizaci√≥n de Flutter a 3.41\nActualizamos la versi√≥n de Flutter en el Dockerfile a 3.41.0, lo que requiri√≥ ajustar los constraints del SDK en `pubspec.yaml` para mantener compatibilidad con la versi√≥n estable de Docker.\n\n---\n\n### üé® Mejoras de UX Web\n\n#### Suggestion Chips en el Chat\nCambiamos los botones de sugerencia del AI Coach de **botones de ancho completo** a **chips con Wrap layout**. Ahora las sugerencias como \"¬øC√≥mo va mi progreso?\", \"Plan semanal\" y \"¬øEstoy estancado?\" se muestran como chips compactos que fluyen naturalmente en la pantalla.\n\n#### WeeklyPlanContent Widget Reutilizable\nCreamos un widget reutilizable (`WeeklyPlanContent`) para renderizar el plan semanal con estilo tanto en la pantalla dedicada como dentro del chat. Antes, el plan en el chat se mostraba como markdown plano.\n\n#### Cache Busting en Nginx\nResolvimos un problema persistente: los usuarios ve√≠an la versi√≥n vieja de la app despu√©s de desplegar. La causa era que `main.dart.js`, `flutter_service_worker.js` y `flutter_bootstrap.js` se cacheaban.\n\nSoluci√≥n:\n- **Service Worker**: Force update en cada carga de p√°gina\n- **Nginx**: `no-cache` para entry points de Flutter, `immutable` para assets est√°ticos\n- **Resultado**: Los usuarios siempre ven la √∫ltima versi√≥n sin necesidad de Cmd+Shift+R\n\n#### Landing Page\nAgregamos links al **website del creador** y **GitHub** en el footer de la landing page de tenk.oventlabs.com.\n\n---\n\n### üìù Blog Biling√ºe\n\nActualizamos el blog del proyecto (este mismo post) para soportar **espa√±ol e ingl√©s**. El sistema usa campos `title_en` y `text_en` en el JSON de entradas, y el rendering en JavaScript detecta el idioma de la p√°gina para mostrar la versi√≥n correcta con `<span class=\"lang-es\">` y `<span class=\"lang-en\">`.\n\n---\n\n### üí° Lo que Aprendimos\n\n1. **Los cron jobs con timezone son complicados** ‚Äî hay que convertir UTC al timezone del usuario en cada ejecuci√≥n, no al rev√©s.\n2. **La idempotencia es esencial** en cron jobs ‚Äî sin el check de `[YYYY-MM-DD]`, un tip podr√≠a generarse m√∫ltiples veces por minuto.\n3. **Docker cachea agresivamente** los builds de Flutter Web ‚Äî siempre usar `--no-cache` para evitar servir JS viejo.\n4. **Los Service Workers son el enemigo del deployment** ‚Äî forzar la actualizaci√≥n en cada carga es la √∫nica forma confiable.\n\n---\n\n**Estado:** TenK en producci√≥n con tips diarios personalizados, dos proveedores de IA con fallback, y una experiencia web pulida. El proyecto avanza r√°pido ‚Äî 9 d√≠as de desarrollo y ya tenemos un producto funcional con IA integrada. üöÄ",
      "text_en": "## Updates from February 12, 2026 ‚Äî Devlog Day 9\n\nToday was a day of complete features deployed to production. The app is now live with AI-generated daily tips, significant UX improvements for the web, and a full deployment to our EC2 server.\n\n---\n\n### üí° Daily Tips: Personalized AI-Generated Tips\n\nWe implemented a **daily tips system automatically generated** by the AI. Every day, at the time the user configures, the AI Coach generates a personalized tip based on their real practice data.\n\n#### How does it work?\n\nA **cron job** runs every minute on the backend. On each execution:\n1. Queries all users who have `dailyTipEnabled = true` and connected AI credentials.\n2. Converts the current UTC time to the **user's timezone** (e.g., `America/Mexico_City`).\n3. If the hour and minute match the user's preferences ‚Üí generates the tip.\n4. It's **idempotent**: before generating, it checks if a tip was already generated today (looking for the `[YYYY-MM-DD]` tag in the last message).\n\n```typescript\n// daily-tip.cron.ts ‚Äî Runs every minute\nconst users = await prisma.user.findMany({\n  where: { dailyTipEnabled: true, claudeCredential: { isNot: null } },\n});\n\nfor (const user of users) {\n  const now = new Date();\n  const userTime = convertToTimezone(now, user.timezone);\n  if (userTime.hours === user.dailyTipHour && userTime.minutes === user.dailyTipMinute) {\n    await generateDailyTip(user.id);\n  }\n}\n```\n\n#### Tip Generation\nThe service pre-loads the user's data in parallel with `Promise.all`:\n- Skills with total hours and mastery levels\n- Journey statistics (weekly average, streaks, projections)\n- The last 5 generated tips (to avoid repetition)\n\nAll this is injected as context into a specialized prompt that generates **a single tip** of maximum 150 words, varying between technical, motivational, and strategic advice.\n\n#### Persistent Conversation\nTips are stored in a `DAILY_TIPS` type conversation ‚Äî a single conversation per user where all historical tips accumulate as messages. This allows the user to browse their advice history.\n\n#### User Preferences\nIn the profile, the user can:\n- **Toggle on/off** daily tips\n- **Select hour and minute** with a time picker\n- The backend stores `dailyTipHour`, `dailyTipMinute`, `dailyTipEnabled` and `timezone`\n\n```prisma\nmodel User {\n  // ... existing fields\n  dailyTipEnabled Boolean  @default(true) @map(\"daily_tip_enabled\")\n  dailyTipHour    Int      @default(8) @map(\"daily_tip_hour\")\n  dailyTipMinute  Int      @default(0) @map(\"daily_tip_minute\")\n  timezone        String   @default(\"America/Mexico_City\")\n}\n```\n\n---\n\n### üöÄ Production Deployment on EC2\n\nWe deployed everything to our AWS EC2 server following the strict protocol:\n\n1. **Mandatory backup** of the database before any changes\n2. **Table counts** before and after (users, skills, sessions, ai_conversations)\n3. **Manual container build** (workaround for the `docker compose --build` bug with `--allow` flag)\n4. **Prisma migrations** with `prisma migrate deploy` (never `reset` in prod)\n5. **Health check** + login test\n\nEverything passed ‚Äî 0 data lost, 3 containers running.\n\n#### Flutter Update to 3.41\nWe updated the Flutter version in the Dockerfile to 3.41.0, which required adjusting the SDK constraints in `pubspec.yaml` to maintain compatibility with Docker's stable version.\n\n---\n\n### üé® Web UX Improvements\n\n#### Suggestion Chips in Chat\nChanged the AI Coach suggestion buttons from **full-width buttons** to **Wrap layout chips**. Now suggestions like \"How's my progress?\", \"Weekly plan\" and \"Am I plateauing?\" display as compact chips that flow naturally on screen.\n\n#### Reusable WeeklyPlanContent Widget\nCreated a reusable widget (`WeeklyPlanContent`) to render the weekly plan with styling both in the dedicated screen and inside the chat. Previously, the plan in chat displayed as plain markdown.\n\n#### Nginx Cache Busting\nResolved a persistent issue: users were seeing the old app version after deploying. The cause was that `main.dart.js`, `flutter_service_worker.js` and `flutter_bootstrap.js` were being cached.\n\nSolution:\n- **Service Worker**: Force update on every page load\n- **Nginx**: `no-cache` for Flutter entry points, `immutable` for static assets\n- **Result**: Users always see the latest version without needing Cmd+Shift+R\n\n#### Landing Page\nAdded **creator website** and **GitHub** links to the tenk.oventlabs.com landing page footer.\n\n---\n\n### üìù Bilingual Blog\n\nUpdated the project blog (this very post) to support **English and Spanish**. The system uses `title_en` and `text_en` fields in the entries JSON, and the JavaScript rendering detects the page language to show the correct version with `<span class=\"lang-es\">` and `<span class=\"lang-en\">`.\n\n---\n\n### üí° What We Learned\n\n1. **Cron jobs with timezones are tricky** ‚Äî you need to convert UTC to the user's timezone on each execution, not the other way around.\n2. **Idempotency is essential** in cron jobs ‚Äî without the `[YYYY-MM-DD]` check, a tip could be generated multiple times per minute.\n3. **Docker caches aggressively** on Flutter Web builds ‚Äî always use `--no-cache` to avoid serving old JS.\n4. **Service Workers are the enemy of deployment** ‚Äî forcing the update on every page load is the only reliable way.\n\n---\n\n**Status:** TenK in production with personalized daily tips, two AI providers with fallback, and a polished web experience. The project is moving fast ‚Äî 9 days of development and we already have a functional product with integrated AI. üöÄ"
    },
    {
      "id": 14,
      "timestamp": "2026-02-13T04:00:00Z",
      "title": "ChatGPT como Tercer Proveedor: Codex API, SSE Streaming y el Bug de item_id",
      "title_en": "ChatGPT as Third Provider: Codex API, SSE Streaming and the item_id Bug",
      "text": "## Avances del 13 de febrero de 2026 ‚Äî Devlog D√≠a 10\n\nHoy integramos **ChatGPT como tercer proveedor de IA** para el AI Coach. Pero no fue tan simple como llamar a la API de OpenAI ‚Äî descubrimos que los suscriptores de Codex usan un endpoint completamente diferente, con un formato de API distinto (Responses API), streaming obligatorio por SSE, y un bug sutil en el parser que nos tom√≥ horas debuggear.\n\n---\n\n### üéØ ¬øPor Qu√© Un Tercer Proveedor?\n\nYa ten√≠amos Claude (prioridad 1) y GitHub Copilot (fallback). Pero quer√≠amos que los usuarios con suscripci√≥n a ChatGPT tambi√©n pudieran usar su propia cuenta. El waterfall ahora es:\n\n```\nClaude ‚Üí Copilot ‚Üí ChatGPT ‚Üí System credentials\n```\n\nTres caminos distintos, un mismo AI Coach.\n\n---\n\n### üîê OAuth PKCE con OpenAI\n\nChatGPT usa **OAuth 2.0 PKCE** ‚Äî el mismo patr√≥n que Claude, pero con sus propias URLs:\n\n```typescript\n// Authorization URL\nhttps://auth.openai.com/authorize?\n  client_id=pdlLIX2Y72MIl2rhLhTE9VV9bN6LJ...\n  &code_challenge=<SHA256_CHALLENGE>\n  &code_challenge_method=S256\n  &redirect_uri=https://tenk.oventlabs.com/api/chatgpt-oauth/callback\n  &response_type=code\n  &scope=openai.chat\n  &state=<STATE>\n\n// Token exchange\nPOST https://auth.openai.com/oauth/token\nContent-Type: application/x-www-form-urlencoded\n```\n\nA diferencia de Claude (que usa JSON body para el token exchange ‚Äî algo √∫nico en la industria), OpenAI sigue el est√°ndar OAuth con `application/x-www-form-urlencoded`.\n\nEl flujo es limpio: el usuario autoriza en auth.openai.com ‚Üí callback con code ‚Üí exchange por access_token + refresh_token ‚Üí guardamos en la DB.\n\n---\n\n### üîç El Descubrimiento: Codex API ‚â† OpenAI API\n\nAqu√≠ viene lo interesante. Inicialmente intentamos llamar al endpoint est√°ndar de OpenAI:\n\n```typescript\n// ‚ùå NO FUNCIONA para suscriptores de Codex\nPOST https://api.openai.com/v1/chat/completions\n‚Üí Error: modelo no disponible para esta suscripci√≥n\n```\n\nResulta que los usuarios con suscripci√≥n a **ChatGPT Plus/Codex** no tienen acceso a la API tradicional. En su lugar, OpenAI expone un endpoint interno diferente:\n\n```typescript\n// ‚úÖ Endpoint correcto para Codex\nPOST https://chatgpt.com/backend-api/codex/responses\n```\n\n¬øLa diferencia? Este endpoint usa la **Responses API** de OpenAI (no la Chat Completions API), con un formato completamente distinto.\n\n---\n\n### üì° Responses API vs. Chat Completions API\n\nLa Chat Completions API (la cl√°sica) usa `messages[]`:\n\n```json\n{\n  \"model\": \"gpt-4o\",\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"Eres un coach...\" },\n    { \"role\": \"user\", \"content\": \"Hola\" }\n  ]\n}\n```\n\nLa Responses API usa `instructions` + `input[]`:\n\n```json\n{\n  \"model\": \"gpt-5.3-codex\",\n  \"instructions\": \"Eres un coach de pr√°ctica deliberada...\",\n  \"input\": [\n    { \"role\": \"user\", \"content\": \"Hola\" },\n    { \"role\": \"assistant\", \"content\": \"¬°Hola! ¬øEn qu√© te ayudo?\" },\n    { \"role\": \"user\", \"content\": \"¬øC√≥mo voy con mi guitarra?\" }\n  ],\n  \"tools\": [...],\n  \"stream\": true\n}\n```\n\nEl system prompt se mueve a `instructions` (fuera del array de mensajes), y el historial va en `input[]`. Tuvimos que implementar `convertToCodexInput()` para transformar nuestro formato interno al formato Responses:\n\n```typescript\nfunction convertToCodexInput(messages: Message[]) {\n  let instructions = '';\n  const input: CodexInput[] = [];\n\n  for (const msg of messages) {\n    if (msg.role === 'system') {\n      instructions += msg.content + '\\n';\n    } else if (msg.role === 'tool') {\n      input.push({\n        type: 'function_call_output',\n        call_id: msg.tool_call_id,\n        output: JSON.stringify(msg.content),\n      });\n    } else {\n      input.push({ role: msg.role, content: msg.content });\n    }\n  }\n\n  return { instructions, input };\n}\n```\n\nNota c√≥mo los mensajes `tool_result` se convierten a `function_call_output` con un `call_id` en vez de `tool_use_id`. Cada API tiene su propia forma de representar lo mismo.\n\n---\n\n### üì∫ Streaming Obligatorio por SSE\n\nA diferencia de Claude y Copilot (donde podemos elegir streaming o no), el endpoint de Codex **requiere `stream: true`** ‚Äî sin streaming, devuelve un cuerpo vac√≠o.\n\nLa respuesta llega como **Server-Sent Events (SSE)**:\n\n```\ndata: {\"type\": \"response.created\", ...}\ndata: {\"type\": \"response.in_progress\", ...}\ndata: {\"type\": \"response.output_item.added\", \"item\": {\"id\": \"fc_abc\", \"call_id\": \"call_xyz\", \"name\": \"get_journey_stats\"}}\ndata: {\"type\": \"response.function_call_arguments.delta\", \"item_id\": \"fc_abc\", \"delta\": \"{\\\"us\"}\ndata: {\"type\": \"response.function_call_arguments.delta\", \"item_id\": \"fc_abc\", \"delta\": \"erId\\\"\"}\ndata: {\"type\": \"response.function_call_arguments.done\", \"item_id\": \"fc_abc\", \"arguments\": \"{\\\"userId\\\": \\\"user123\\\"}\"}\ndata: {\"type\": \"response.completed\", \"response\": {\"usage\": {\"input_tokens\": 1234}}}\n```\n\nImplementamos `parseCodexStream()` que acumula los deltas de cada tool call y extrae el contenido de texto:\n\n```typescript\nasync function parseCodexStream(response: Response) {\n  const reader = response.body!.getReader();\n  const decoder = new TextDecoder();\n  let buffer = '';\n  let content = '';\n  const argBuffers: Record<string, string> = {};\n  const toolCalls: ToolCall[] = [];\n\n  while (true) {\n    const { done, value } = await reader.read();\n    if (done) break;\n    buffer += decoder.decode(value, { stream: true });\n\n    // Parsear l√≠neas SSE\n    const lines = buffer.split('\\n');\n    buffer = lines.pop() || '';\n\n    for (const line of lines) {\n      if (!line.startsWith('data: ')) continue;\n      const evt = JSON.parse(line.slice(6));\n\n      switch (evt.type) {\n        case 'response.output_text.delta':\n          content += evt.delta;\n          break;\n        case 'response.function_call_arguments.delta':\n          const key = evt.item_id || evt.call_id;\n          argBuffers[key] = (argBuffers[key] || '') + evt.delta;\n          break;\n        // ... m√°s eventos\n      }\n    }\n  }\n\n  return { content: content || null, toolCalls };\n}\n```\n\n---\n\n### üêõ El Bug de item_id vs. call_id\n\nEste fue el bug m√°s dif√≠cil de encontrar. El primer mensaje siempre funcionaba, pero los siguientes retornaban *\"No pude generar una respuesta.\"*\n\n#### El S√≠ntoma\nLos logs mostraban:\n```\ncontent: null, toolCallsCount: 0, textPartsCount: 0\n```\n\nEl modelo quer√≠a llamar herramientas (como `get_journey_stats`), pero el parser no capturaba nada.\n\n#### La Causa\nLos eventos SSE de Codex usan **campos diferentes** seg√∫n el tipo de evento:\n\n- `response.output_item.added` ‚Üí contiene `item.id` (ej: `\"fc_abc\"`) y `item.call_id` (ej: `\"call_xyz\"`)\n- `response.function_call_arguments.delta` ‚Üí contiene `item_id` (ej: `\"fc_abc\"`) ‚Äî **NO `call_id`**\n\nNuestro parser original buscaba `evt.call_id` en los deltas, pero ese campo **no existe** en los eventos delta. Solo existe `item_id`. Como resultado, los argumentos de las tool calls se acumulaban bajo una key `undefined`, y al armar las tool calls finales, no encontraba nada.\n\n#### La Soluci√≥n\nCreamos un mapa `itemIdToCallId` que conecta ambos identificadores:\n\n```typescript\nconst itemIdToCallId = new Map<string, string>();\n\n// Cuando llega output_item.added, registramos el mapeo\ncase 'response.output_item.added':\n  if (item.type === 'function_call') {\n    itemIdToCallId.set(item.id, item.call_id);\n  }\n  break;\n\n// En los deltas, usamos item_id como key\ncase 'response.function_call_arguments.delta':\n  const key = evt.item_id || evt.call_id;\n  argBuffers[key] = (argBuffers[key] || '') + evt.delta;\n  break;\n\n// Al armar la tool call final, resolvemos el call_id real\ncase 'response.function_call_arguments.done':\n  const resolvedCallId = itemIdToCallId.get(evt.item_id) || evt.call_id;\n  toolCalls.push({\n    id: resolvedCallId,  // El call_id que necesita el agent loop\n    name: toolName,\n    arguments: parsedArgs,\n  });\n  break;\n```\n\nEl `call_id` es crucial porque el agent loop lo necesita para enviar el `tool_result` de vuelta al modelo en la siguiente iteraci√≥n.\n\n---\n\n### üîë Header Secreto: chatgpt-account-id\n\nEl endpoint de Codex requiere un header especial: `chatgpt-account-id`. Este ID no se env√≠a al autorizar ‚Äî hay que **extraerlo del JWT** del access token:\n\n```typescript\nfunction extractAccountIdFromJwt(token: string): string {\n  const payload = JSON.parse(\n    Buffer.from(token.split('.')[1], 'base64url').toString()\n  );\n  return payload['https://api.openai.com/auth']?.user_id\n    || payload.sub;\n}\n```\n\nSin este header, la API devuelve 403. Otro detalle no documentado.\n\n---\n\n### üìä Comparaci√≥n: Tres Proveedores, Tres Mundos\n\n| Aspecto | Claude | Copilot | ChatGPT/Codex |\n|---------|--------|---------|---------------|\n| Auth | OAuth PKCE | Device Flow | OAuth PKCE |\n| Token exchange | JSON body (√∫nico) | form-urlencoded | form-urlencoded |\n| API endpoint | api.claude.ai | api.github.com ‚Üí JWT | chatgpt.com/backend-api |\n| API format | Messages API | Chat Completions | Responses API |\n| Streaming | Opcional | Opcional | **Obligatorio** |\n| System prompt | `system` message | `system` message | `instructions` field |\n| Tool results | `tool_result` + `tool_use_id` | `tool` + `tool_call_id` | `function_call_output` + `call_id` |\n| Modelo | claude-sonnet-4.5 | claude-sonnet-4.5 | gpt-5.3-codex |\n| Quirks | `code#state` sin doc | 2-token system | `item_id` ‚â† `call_id` |\n\nCada proveedor tiene su propio universo de autenticaci√≥n, formato de API y peculiaridades. Nuestro backend abstrae todo esto ‚Äî el agent runner no sabe ni le importa qu√© proveedor respondi√≥.\n\n---\n\n### üóëÔ∏è Eliminar Conversaciones\n\nAprovechamos para implementar **eliminar conversaciones** del AI Coach. El usuario puede deslizar (swipe-to-delete) cualquier conversaci√≥n en la lista lateral:\n\n- Swipe de derecha a izquierda ‚Üí fondo rojo con √≠cono de basura\n- Confirmaci√≥n con dialog: *\"¬øEliminar 't√≠tulo de conversaci√≥n'?\"*\n- Las conversaciones de Daily Tips NO se pueden eliminar\n- Si la conversaci√≥n eliminada es la actual, se limpia la vista\n\n---\n\n### üîÑ Fix: Status Chip en Tiempo Real\n\nTen√≠amos un bug donde el chip de estado en el header (\"AI Conectado/Desconectado\") no se actualizaba despu√©s de conectar un proveedor desde la pantalla del chat. El usuario conectaba ChatGPT ‚Üí el chat funcionaba ‚Üí pero el chip segu√≠a mostrando \"Desconectado\".\n\nLa causa: el `EmbeddedAiChatPage` actualizaba su estado interno pero no notificaba al `HomeWebLayout` padre. La soluci√≥n fue agregar un callback `onConnectionChanged` que dispara `_checkAiStatus()` en el layout padre.\n\n---\n\n### üí° Lo que Aprendimos\n\n1. **No todas las APIs de OpenAI son iguales** ‚Äî la API de `api.openai.com` es para API keys de pago, los suscriptores de ChatGPT usan un endpoint interno con formato diferente.\n2. **Responses API ‚â† Chat Completions API** ‚Äî el system prompt va en `instructions`, los tool results son `function_call_output`, y streaming es obligatorio.\n3. **Los IDs en SSE pueden ser confusos** ‚Äî `item_id` y `call_id` son cosas diferentes que apuntan al mismo tool call. Sin mapearlos, los tool calls se pierden silenciosamente.\n4. **Debug logging en producci√≥n salva vidas** ‚Äî sin los logs detallados de cada evento SSE, habr√≠a sido imposible encontrar el bug de `item_id`.\n5. **Tres proveedores, un Coach** ‚Äî la abstracci√≥n del backend es lo que permite que el agente funcione igual sin importar qui√©n responde.\n\n---\n\n**Estado:** TenK ahora tiene **tres proveedores de IA**: Claude, GitHub Copilot y ChatGPT. El waterfall de 4 niveles asegura que el AI Coach siempre tenga un camino. Cada proveedor tiene su propia auth, su propio formato de API, y sus propios quirks ‚Äî pero desde la perspectiva del usuario, todo es un solo coach que nunca falla. üöÄ",
      "text_en": "## Updates from February 13, 2026 ‚Äî Devlog Day 10\n\nToday we integrated **ChatGPT as the third AI provider** for the AI Coach. But it wasn't as simple as calling the OpenAI API ‚Äî we discovered that Codex subscribers use a completely different endpoint, with a different API format (Responses API), mandatory SSE streaming, and a subtle parser bug that took hours to debug.\n\n---\n\n### üéØ Why a Third Provider?\n\nWe already had Claude (priority 1) and GitHub Copilot (fallback). But we wanted users with a ChatGPT subscription to also be able to use their own account. The waterfall is now:\n\n```\nClaude ‚Üí Copilot ‚Üí ChatGPT ‚Üí System credentials\n```\n\nThree different paths, one AI Coach.\n\n---\n\n### üîê OAuth PKCE with OpenAI\n\nChatGPT uses **OAuth 2.0 PKCE** ‚Äî the same pattern as Claude, but with its own URLs:\n\n```typescript\n// Authorization URL\nhttps://auth.openai.com/authorize?\n  client_id=pdlLIX2Y72MIl2rhLhTE9VV9bN6LJ...\n  &code_challenge=<SHA256_CHALLENGE>\n  &code_challenge_method=S256\n  &redirect_uri=https://tenk.oventlabs.com/api/chatgpt-oauth/callback\n  &response_type=code\n  &scope=openai.chat\n  &state=<STATE>\n\n// Token exchange\nPOST https://auth.openai.com/oauth/token\nContent-Type: application/x-www-form-urlencoded\n```\n\nUnlike Claude (which uses JSON body for token exchange ‚Äî something unique in the industry), OpenAI follows the OAuth standard with `application/x-www-form-urlencoded`.\n\nThe flow is clean: user authorizes at auth.openai.com ‚Üí callback with code ‚Üí exchange for access_token + refresh_token ‚Üí save to DB.\n\n---\n\n### üîç The Discovery: Codex API ‚â† OpenAI API\n\nHere's where it gets interesting. Initially we tried calling the standard OpenAI endpoint:\n\n```typescript\n// ‚ùå DOESN'T WORK for Codex subscribers\nPOST https://api.openai.com/v1/chat/completions\n‚Üí Error: model not available for this subscription\n```\n\nIt turns out that users with a **ChatGPT Plus/Codex** subscription don't have access to the traditional API. Instead, OpenAI exposes a different internal endpoint:\n\n```typescript\n// ‚úÖ Correct endpoint for Codex\nPOST https://chatgpt.com/backend-api/codex/responses\n```\n\nThe difference? This endpoint uses the **Responses API** (not the Chat Completions API), with a completely different format.\n\n---\n\n### üì° Responses API vs. Chat Completions API\n\nThe Chat Completions API (the classic one) uses `messages[]`:\n\n```json\n{\n  \"model\": \"gpt-4o\",\n  \"messages\": [\n    { \"role\": \"system\", \"content\": \"You are a coach...\" },\n    { \"role\": \"user\", \"content\": \"Hello\" }\n  ]\n}\n```\n\nThe Responses API uses `instructions` + `input[]`:\n\n```json\n{\n  \"model\": \"gpt-5.3-codex\",\n  \"instructions\": \"You are a deliberate practice coach...\",\n  \"input\": [\n    { \"role\": \"user\", \"content\": \"Hello\" },\n    { \"role\": \"assistant\", \"content\": \"Hi! How can I help?\" },\n    { \"role\": \"user\", \"content\": \"How's my guitar going?\" }\n  ],\n  \"tools\": [...],\n  \"stream\": true\n}\n```\n\nThe system prompt moves to `instructions` (outside the message array), and history goes in `input[]`. We had to implement `convertToCodexInput()` to transform our internal format to the Responses format:\n\n```typescript\nfunction convertToCodexInput(messages: Message[]) {\n  let instructions = '';\n  const input: CodexInput[] = [];\n\n  for (const msg of messages) {\n    if (msg.role === 'system') {\n      instructions += msg.content + '\\n';\n    } else if (msg.role === 'tool') {\n      input.push({\n        type: 'function_call_output',\n        call_id: msg.tool_call_id,\n        output: JSON.stringify(msg.content),\n      });\n    } else {\n      input.push({ role: msg.role, content: msg.content });\n    }\n  }\n\n  return { instructions, input };\n}\n```\n\nNote how `tool_result` messages become `function_call_output` with a `call_id` instead of `tool_use_id`. Each API has its own way of representing the same thing.\n\n---\n\n### üì∫ Mandatory SSE Streaming\n\nUnlike Claude and Copilot (where we can choose streaming or not), the Codex endpoint **requires `stream: true`** ‚Äî without streaming, it returns an empty body.\n\nThe response arrives as **Server-Sent Events (SSE)**:\n\n```\ndata: {\"type\": \"response.created\", ...}\ndata: {\"type\": \"response.in_progress\", ...}\ndata: {\"type\": \"response.output_item.added\", \"item\": {\"id\": \"fc_abc\", \"call_id\": \"call_xyz\", \"name\": \"get_journey_stats\"}}\ndata: {\"type\": \"response.function_call_arguments.delta\", \"item_id\": \"fc_abc\", \"delta\": \"{\\\"us\"}\ndata: {\"type\": \"response.function_call_arguments.delta\", \"item_id\": \"fc_abc\", \"delta\": \"erId\\\"\"}\ndata: {\"type\": \"response.function_call_arguments.done\", \"item_id\": \"fc_abc\", \"arguments\": \"{\\\"userId\\\": \\\"user123\\\"}\"}\ndata: {\"type\": \"response.completed\", \"response\": {\"usage\": {\"input_tokens\": 1234}}}\n```\n\nWe implemented `parseCodexStream()` which accumulates deltas for each tool call and extracts text content.\n\n---\n\n### üêõ The item_id vs. call_id Bug\n\nThis was the hardest bug to find. The first message always worked, but follow-up messages returned *\"I couldn't generate a response.\"*\n\n#### The Symptom\nLogs showed:\n```\ncontent: null, toolCallsCount: 0, textPartsCount: 0\n```\n\nThe model wanted to call tools (like `get_journey_stats`), but the parser captured nothing.\n\n#### The Cause\nCodex SSE events use **different fields** depending on the event type:\n\n- `response.output_item.added` ‚Üí contains `item.id` (e.g., `\"fc_abc\"`) and `item.call_id` (e.g., `\"call_xyz\"`)\n- `response.function_call_arguments.delta` ‚Üí contains `item_id` (e.g., `\"fc_abc\"`) ‚Äî **NOT `call_id`**\n\nOur original parser looked for `evt.call_id` in deltas, but that field **doesn't exist** in delta events. Only `item_id` exists. As a result, tool call arguments accumulated under an `undefined` key, and when assembling the final tool calls, nothing was found.\n\n#### The Fix\nWe created an `itemIdToCallId` map that bridges both identifiers:\n\n```typescript\nconst itemIdToCallId = new Map<string, string>();\n\n// When output_item.added arrives, register the mapping\ncase 'response.output_item.added':\n  if (item.type === 'function_call') {\n    itemIdToCallId.set(item.id, item.call_id);\n  }\n  break;\n\n// In deltas, use item_id as key\ncase 'response.function_call_arguments.delta':\n  const key = evt.item_id || evt.call_id;\n  argBuffers[key] = (argBuffers[key] || '') + evt.delta;\n  break;\n\n// When assembling the final tool call, resolve the real call_id\ncase 'response.function_call_arguments.done':\n  const resolvedCallId = itemIdToCallId.get(evt.item_id) || evt.call_id;\n  toolCalls.push({\n    id: resolvedCallId,  // The call_id needed by the agent loop\n    name: toolName,\n    arguments: parsedArgs,\n  });\n  break;\n```\n\nThe `call_id` is crucial because the agent loop needs it to send the `tool_result` back to the model in the next iteration.\n\n---\n\n### üîë Secret Header: chatgpt-account-id\n\nThe Codex endpoint requires a special header: `chatgpt-account-id`. This ID is not sent during authorization ‚Äî you have to **extract it from the JWT** access token:\n\n```typescript\nfunction extractAccountIdFromJwt(token: string): string {\n  const payload = JSON.parse(\n    Buffer.from(token.split('.')[1], 'base64url').toString()\n  );\n  return payload['https://api.openai.com/auth']?.user_id\n    || payload.sub;\n}\n```\n\nWithout this header, the API returns 403. Another undocumented detail.\n\n---\n\n### üìä Comparison: Three Providers, Three Worlds\n\n| Aspect | Claude | Copilot | ChatGPT/Codex |\n|--------|--------|---------|---------------|\n| Auth | OAuth PKCE | Device Flow | OAuth PKCE |\n| Token exchange | JSON body (unique) | form-urlencoded | form-urlencoded |\n| API endpoint | api.claude.ai | api.github.com ‚Üí JWT | chatgpt.com/backend-api |\n| API format | Messages API | Chat Completions | Responses API |\n| Streaming | Optional | Optional | **Mandatory** |\n| System prompt | `system` message | `system` message | `instructions` field |\n| Tool results | `tool_result` + `tool_use_id` | `tool` + `tool_call_id` | `function_call_output` + `call_id` |\n| Model | claude-sonnet-4.5 | claude-sonnet-4.5 | gpt-5.3-codex |\n| Quirks | Undocumented `code#state` | 2-token system | `item_id` ‚â† `call_id` |\n\nEach provider has its own authentication universe, API format, and quirks. Our backend abstracts all of this ‚Äî the agent runner doesn't know or care which provider responded.\n\n---\n\n### üóëÔ∏è Delete Conversations\n\nWe also implemented **conversation deletion** for the AI Coach. Users can swipe-to-delete any conversation in the side list:\n\n- Swipe right to left ‚Üí red background with trash icon\n- Confirmation dialog: *\"Delete 'conversation title'?\"*\n- Daily Tips conversations CANNOT be deleted\n- If the deleted conversation is the current one, the view is cleared\n\n---\n\n### üîÑ Fix: Real-Time Status Chip\n\nWe had a bug where the header status chip (\"AI Connected/Disconnected\") didn't update after connecting a provider from the chat screen. The user would connect ChatGPT ‚Üí chat worked ‚Üí but the chip still showed \"Disconnected\".\n\nThe cause: `EmbeddedAiChatPage` updated its internal state but didn't notify the parent `HomeWebLayout`. The fix was adding an `onConnectionChanged` callback that triggers `_checkAiStatus()` in the parent layout.\n\n---\n\n### üí° What We Learned\n\n1. **Not all OpenAI APIs are the same** ‚Äî `api.openai.com` is for paid API keys, ChatGPT subscribers use an internal endpoint with a different format.\n2. **Responses API ‚â† Chat Completions API** ‚Äî the system prompt goes in `instructions`, tool results are `function_call_output`, and streaming is mandatory.\n3. **SSE IDs can be confusing** ‚Äî `item_id` and `call_id` are different things pointing to the same tool call. Without mapping them, tool calls are silently lost.\n4. **Production debug logging saves lives** ‚Äî without detailed logs of each SSE event, finding the `item_id` bug would have been impossible.\n5. **Three providers, one Coach** ‚Äî the backend abstraction is what allows the agent to work the same regardless of who responds.\n\n---\n\n**Status:** TenK now has **three AI providers**: Claude, GitHub Copilot, and ChatGPT. The 4-level waterfall ensures the AI Coach always has a path. Each provider has its own auth, its own API format, and its own quirks ‚Äî but from the user's perspective, it's all one coach that never fails. üöÄ"
    }
  ]
}
